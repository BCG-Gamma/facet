{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "**This notebook serves as a demo and tutorial for the yielengine package.**\n",
    "It illustrates the following methods:\n",
    "- EDA\n",
    "- Boruta feature selection\n",
    "- Shap clustering feature selection\n",
    "- simulaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:14.834234Z",
     "start_time": "2019-07-17T08:00:14.821240Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the used verion of Python to be sure that you are using the yield-engine environement\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:14.974212Z",
     "start_time": "2019-07-17T08:00:14.967212Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_YIELD_ENGINE = 'src'\n",
    "\n",
    "def set_paths() -> None:\n",
    "    \"\"\"\n",
    "    set correct working directory and python path when started from within PyCharm\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    if 'cwd' not in globals():\n",
    "        # noinspection PyGlobalUndefined\n",
    "        global cwd\n",
    "        cwd = os.path.join(os.getcwd(), os.pardir)\n",
    "        os.chdir(cwd)\n",
    "    \n",
    "    print(f\"working dir is '{os.getcwd()}'\")\n",
    "                             \n",
    "    if PATH_YIELD_ENGINE not in sys.path:\n",
    "        sys.path.insert(0, PATH_YIELD_ENGINE)\n",
    "    \n",
    "    print(f\"added `{sys.path[0]}` to python paths\")\n",
    "\n",
    "set_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:26.450346Z",
     "start_time": "2019-07-17T08:00:15.005207Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os    \n",
    "import re\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error\n",
    "from typing import *\n",
    "\n",
    "from yieldengine import Sample\n",
    "from yieldengine.dendrogram import DendrogramDrawer\n",
    "from yieldengine.dendrogram.style import FeatMapStyle, LineStyle\n",
    "from yieldengine.df.pipeline import PipelineDF\n",
    "from yieldengine.preprocessing.encode import OneHotEncoderDF\n",
    "from yieldengine.preprocessing.impute import SimpleImputerDF, MissingIndicatorDF\n",
    "from yieldengine.preprocessing.selection import BorutaDF\n",
    "from yieldengine.preprocessing.compose import ColumnTransformerDF\n",
    "from yieldengine.model.inspection import ModelInspector\n",
    "from yieldengine.model.prediction import ModelFitCV\n",
    "from yieldengine.model.selection import Model, ModelGrid, ModelRanker, summary_report, ModelEvaluation, ModelScoring\n",
    "from yieldengine.model.validation import CircularCrossValidator\n",
    "from yieldengine.visualization.eda import plot_ecdf, plot_ecdf_df, plot_hist_df\n",
    "from yieldengine.preprocessing.outlier import OutlierRemoverDF\n",
    "from yieldengine.preprocessing import FunctionTransformerDF\n",
    "from yieldengine.simulation import UnivariateSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:26.459348Z",
     "start_time": "2019-07-17T08:00:26.452304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enlarge the width of the cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:26.476301Z",
     "start_time": "2019-07-17T08:00:26.462306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only show matplolib warning logging messages, otherwise there are too many\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:26.492333Z",
     "start_time": "2019-07-17T08:00:26.479301Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:26.499298Z",
     "start_time": "2019-07-17T08:00:26.495298Z"
    }
   },
   "outputs": [],
   "source": [
    "IQR_THRESHOLD = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data, EDA and data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:26.570286Z",
     "start_time": "2019-07-17T08:00:26.502298Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('data', 'ames-housing-dataset')\n",
    "RAW_DATA_CSV = os.path.join(DATA_DIR, 'train.csv')\n",
    "TARGET = \"SalePrice\"\n",
    "\n",
    "print(f\"Read {RAW_DATA_CSV}\")\n",
    "raw_df = pd.read_csv(RAW_DATA_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:26.635276Z",
     "start_time": "2019-07-17T08:00:26.572287Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Shape of the raw data: {raw_df.shape}\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:26.647273Z",
     "start_time": "2019-07-17T08:00:26.640276Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the variables\n",
    "The variable *description_dict* is a dictionary whose keys are the column names of the dataset and the values are description of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:27.196188Z",
     "start_time": "2019-07-17T08:00:26.651274Z"
    }
   },
   "outputs": [],
   "source": [
    "DESCRIPTION = os.path.join(DATA_DIR, 'data_description.txt')\n",
    "with open(DESCRIPTION, 'r') as f:\n",
    "    description = f.read()\n",
    "\n",
    "# Create a dictionary containing description of the variables\n",
    "splitted = description.split()\n",
    "idx_begin = [i for i, w in enumerate(description.split()) if w.endswith(':')]\n",
    "description_dict = {\n",
    "       splitted[idx_begin[i]][:-1]: ' '.join(splitted[idx_begin[i]+1: idx_begin[i+1]]) for i in range(len(idx_begin)-1)\n",
    "}\n",
    "\n",
    "pprint.pprint(description_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by sold date\n",
    "We sort the samples by selling date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:27.684104Z",
     "start_time": "2019-07-17T08:00:27.215179Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tmp = raw_df.copy()\n",
    "df_tmp['YrSold'].value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:28.253042Z",
     "start_time": "2019-07-17T08:00:27.687104Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tmp['DateSold'] = pd.to_datetime(df_tmp['YrSold']*100 + df_tmp['MoSold'], format='%Y%m')\n",
    "df_tmp.groupby('DateSold')[TARGET].mean().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:28.267007Z",
     "start_time": "2019-07-17T08:00:28.255006Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = raw_df.copy()\n",
    "# Sort by the date\n",
    "dataset_df = dataset_df.sort_values(by=['YrSold', 'MoSold'])\n",
    "# Drop the Id column and date columns\n",
    "dataset_df = dataset_df.drop(['Id', 'YrSold', 'MoSold'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:28.319043Z",
     "start_time": "2019-07-17T08:00:28.270006Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove infinity values\n",
    "dataset_df = dataset_df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the types of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:28.369994Z",
     "start_time": "2019-07-17T08:00:28.321995Z"
    }
   },
   "outputs": [],
   "source": [
    "features_df = dataset_df.drop(columns=TARGET)\n",
    "cat_features = features_df.select_dtypes(['category', object]).columns\n",
    "num_features = features_df.select_dtypes('number').columns\n",
    "print (f\"{features_df.shape[1] - len(cat_features) - len(num_features)} not a number or category\")\n",
    "del features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:28.622947Z",
     "start_time": "2019-07-17T08:00:28.372992Z"
    }
   },
   "outputs": [],
   "source": [
    "for col_name in cat_features:\n",
    "    dataset_df.loc[:, col_name] = (\n",
    "        dataset_df.loc[:, col_name].astype(object).fillna('missing value').astype(str).str.strip().str.lower().astype('category')\n",
    "    )\n",
    "# output datasets\n",
    "dt = dataset_df.dtypes.rename('dtype').astype(str)\n",
    "dt.groupby(by=dt.values).count().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity we select only numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:28.636943Z",
     "start_time": "2019-07-17T08:00:28.625945Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = dataset_df[list(num_features) + [TARGET]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T15:37:32.105528Z",
     "start_time": "2019-06-19T15:37:32.089954Z"
    }
   },
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:28.647941Z",
     "start_time": "2019-07-17T08:00:28.639943Z"
    }
   },
   "outputs": [],
   "source": [
    "outlier_remover = OutlierRemoverDF(iqr_multiple=IQR_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:28.689938Z",
     "start_time": "2019-07-17T08:00:28.650940Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out the rows of the dataset where the target is  an outlier\n",
    "print(f\"Shape before removal of target outlier: {dataset_df.shape}\")\n",
    "mask = outlier_remover.fit_transform(dataset_df[[TARGET]])[TARGET].notna()\n",
    "dataset_df = dataset_df.loc[mask, :]\n",
    "print(f\"Shape after removal of target outlier: {dataset_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample object to be used by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:28.697935Z",
     "start_time": "2019-07-17T08:00:28.692934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a Sample object to be used by our model\n",
    "sample_full = Sample(\n",
    "    observations=dataset_df,\n",
    "    target_name=TARGET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot of the empirical cumulative distribution function (ECDF) of the target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T08:00:39.810091Z",
     "start_time": "2019-07-17T08:00:39.581124Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ecdf(sample_full.target, iqr_multiple=1., iqr_multiple_far=None ,color_outlier='black', markersize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imputation and encoding\n",
    "We first define a Pipeline that will be used before running Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:39:47.110063Z",
     "start_time": "2019-06-28T08:39:47.078825Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_preprocessor(sample: Sample, onehot: bool = True, missing: bool = True) -> ColumnTransformerDF:\n",
    "    tx = []\n",
    "    # define how features should be preprocessed\n",
    "    tx.append((\"impute\", \n",
    "               SimpleImputerDF(strategy=\"median\"), \n",
    "               sample.features_by_type(Sample.DTYPE_NUMERICAL).columns))\n",
    "\n",
    "    if missing:\n",
    "        tx.append((\"missing\", \n",
    "                   MissingIndicatorDF(error_on_new=False), \n",
    "                   sample.features_by_type(Sample.DTYPE_NUMERICAL).columns))\n",
    "        \n",
    "    if onehot:\n",
    "        tx.append((\"onehot\", \n",
    "                   OneHotEncoderDF(sparse=False, handle_unknown=\"ignore\"),\n",
    "                   sample.features_by_type([Sample.DTYPE_CATEGORICAL]).columns))     \n",
    "\n",
    "    return ColumnTransformerDF(transformers=tx)\n",
    "\n",
    "def make_outlier_transformer(sample: Sample, iqr_threshold) -> ColumnTransformerDF:    \n",
    "    outlier_transformers = [\n",
    "        ('outlier', TukeyOutlierRemoverDF(iqr_threshold=2), sample_full.features_by_type(Sample.DTYPE_NUMERICAL).columns),\n",
    "        ('rest', FunctionTransformerDF(validate=False), sample_full.features_by_type(Sample.DTYPE_OBJECT).columns)\n",
    "    ]\n",
    "    outlier_step = ColumnTransformerDF(transformers=outlier_transformers)\n",
    "    return outlier_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:39:47.156932Z",
     "start_time": "2019-06-28T08:39:47.110063Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = make_preprocessor(sample=sample_full, missing=True, onehot=True)\n",
    "outlier_step = make_outlier_transformer(sample=sample_full, iqr_threshold=IQR_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection (Boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:39:47.172555Z",
     "start_time": "2019-06-28T08:39:47.156932Z"
    }
   },
   "outputs": [],
   "source": [
    "boruta_selector = PipelineDF(\n",
    "    steps = [\n",
    "        ('outlier_removal', outlier_step),\n",
    "        ('preprocess', preprocessor),\n",
    "        ('boruta', BorutaDF(estimator=RandomForestRegressor(max_depth=5,min_samples_leaf=8,\n",
    "                                                            random_state=42,n_jobs=-3),\n",
    "                             n_estimators='auto', verbose=2, max_iter=100, random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:40:39.340250Z",
     "start_time": "2019-06-28T08:39:47.172555Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boruta_selector.fit(sample_full.features, sample_full.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:40:39.387087Z",
     "start_time": "2019-06-28T08:40:39.340250Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected = sorted(list(set(boruta_selector.columns_original)))\n",
    "print(\"List of the features selected by Boruta:\\n\")\n",
    "pprint.pprint(list(selected))\n",
    "if selected is None:\n",
    "    raise Error(\"You need to specify a backup set of variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a new sample object containing only the features selected by Boruta. \n",
    "- Before Boruta: 34 numercial features\n",
    "- After Boruta: 18 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:40:39.402711Z",
     "start_time": "2019-06-28T08:40:39.387087Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = sample_full.select_features(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization of numerical features and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:40:42.730193Z",
     "start_time": "2019-06-28T08:40:39.402711Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ecdf_df(sample.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search and cross validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:40:42.750356Z",
     "start_time": "2019-06-28T08:40:42.732194Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the circular cross validator with 30 folds\n",
    "circular_cv = CircularCrossValidator(test_ratio=1/3, num_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:40:42.797189Z",
     "start_time": "2019-06-28T08:40:42.750356Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_grids(sample: Sample) -> List[ModelGrid]:\n",
    "    grids = [ModelGrid(\n",
    "         model=Model(estimator=RandomForestRegressor(random_state=42),\n",
    "                     preprocessing=make_preprocessor(sample=sample, missing=False)),\n",
    "         estimator_parameters = {\"n_estimators\": [1000],\n",
    "                                 \"max_depth\": [4,5,6],\n",
    "                                 \"min_samples_leaf\": [4],\n",
    "                                 \"criterion\": [\"mse\"], #[\"mae\",\"mse\"],\n",
    "                                 \"max_features\": [0.4, 0.7, 1.0]})]\n",
    "    return grids\n",
    "grids = get_model_grids(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:09.521380Z",
     "start_time": "2019-06-28T08:40:42.797189Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ranker = ModelRanker(grids=grids, cv=circular_cv)\n",
    "ranking = ranker.run(sample, n_jobs=-3)\n",
    "print(summary_report(ranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:09.536999Z",
     "start_time": "2019-06-28T08:41:09.521380Z"
    }
   },
   "outputs": [],
   "source": [
    "top_model = ranking[0]\n",
    "print(top_model.scoring['test_score'])\n",
    "print(top_model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:17.463900Z",
     "start_time": "2019-06-28T08:41:09.536999Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor = PredictorCV(model=top_model.model, cv=circular_cv, sample=sample)\n",
    "inspector = ModelInspector(predictor)\n",
    "predictions = predictor.predictions_for_all_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:17.838778Z",
     "start_time": "2019-06-28T08:41:17.463900Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(sample.target.sort_index(), \n",
    "            predictions.groupby(predictions.index)['prediction'].mean().sort_index(), alpha=.3)\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:18.151288Z",
     "start_time": "2019-06-28T08:41:17.838778Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions['error'] = (predictions['target'] - predictions['prediction'])\n",
    "plt.scatter(x=predictions.index.values, y=predictions['error'].values, alpha=.2)\n",
    "plt.xlabel(\"House index (ordered by sold date)\")\n",
    "plt.ylabel(\"Prediction error\")\n",
    "plt.axhline(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:34.444886Z",
     "start_time": "2019-06-28T08:41:18.151288Z"
    }
   },
   "outputs": [],
   "source": [
    "M = inspector.shap_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:34.460465Z",
     "start_time": "2019-06-28T08:41:34.444886Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number_features = predictor.sample.features.shape[1]\n",
    "# _ = M.plot(subplots=True, figsize=(10, number_features*7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:34.491749Z",
     "start_time": "2019-06-28T08:41:34.460465Z"
    }
   },
   "outputs": [],
   "source": [
    "inspector.shap_matrix().head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:34.788566Z",
     "start_time": "2019-06-28T08:41:34.491749Z"
    }
   },
   "outputs": [],
   "source": [
    "depm = inspector.feature_dependency_matrix()\n",
    "plt.pcolormesh(depm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:34.819809Z",
     "start_time": "2019-06-28T08:41:34.788566Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspector.feature_importances().sort_values(ascending=False).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:34.851060Z",
     "start_time": "2019-06-28T08:41:34.819809Z"
    }
   },
   "outputs": [],
   "source": [
    "linkage_tree = inspector.cluster_dependent_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:36.388260Z",
     "start_time": "2019-06-28T08:41:34.851060Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_features = predictor.sample.features.shape[1]\n",
    "ax = plt.figure(figsize=(10, number_features*.5)).add_subplot(111)\n",
    "style = FeatMapStyle(ax)\n",
    "DendrogramDrawer(title=TARGET, linkage_tree=linkage_tree, style=style).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:37.028825Z",
     "start_time": "2019-06-28T08:41:36.388260Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10,number_features*0.5)).add_subplot(111)\n",
    "style = LineStyle(ax)\n",
    "DendrogramDrawer(title=TARGET, linkage_tree=linkage_tree, style=style).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap clustering iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method the run an iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:37.044449Z",
     "start_time": "2019-06-28T08:41:37.028825Z"
    }
   },
   "outputs": [],
   "source": [
    "def shap_clustering_iteration(sample: Sample, black_list: List[str]) -> Tuple[Sample, ModelInspector]:\n",
    "    \"\"\"Removing black list features, and retrain the model. Return a new sample and a fitted model inspector.\"\"\"\n",
    "    # Create a new Sample by removing the features in the blacklist\n",
    "    features = sample.feature_names\n",
    "    if not set(black_list) <= features:\n",
    "        log.warning(f\"\"\"The black list must be a subset of the set of features: the features \n",
    "        {set(black_list)-set(features)} are in black list but not in the features.\"\"\")\n",
    "\n",
    "    white_list = sorted(list(set(features) - set(black_list)))\n",
    "    log.info(f\"New white list:\\n {white_list}\")\n",
    "    new_sample = sample.select_features(white_list)\n",
    "    \n",
    "    # Create the preprocessing pipeline for the model run\n",
    "    outlier_step = make_outlier_transformer(sample=new_sample, iqr_threshold=IQR_THRESHOLD)\n",
    "    preprocessor = make_preprocessor(sample=new_sample, missing=True, onehot=True)\n",
    "    pipeline = PipelineDF(steps = [('outlier_removal', outlier_step), ('preprocess', preprocessor)])\n",
    "    \n",
    "    # Run the pipeline\n",
    "    grids = get_model_grids(new_sample)\n",
    "    ranker = ModelRanker(grids=grids, cv=circular_cv)\n",
    "    ranking = ranker.run(new_sample, n_jobs=-3)\n",
    "    top_model = ranking[0]\n",
    "    \n",
    "    # Report the model result\n",
    "    print(summary_report(ranking))\n",
    "    print(f\"top_model score: {top_model.scoring['test_score']}\")\n",
    "    print(f\"top_model parameters: {top_model.parameters}\")\n",
    "    predictor = PredictorCV(model=top_model.model, cv=circular_cv, sample=new_sample)\n",
    "    inspector = ModelInspector(predictor)\n",
    "    \n",
    "    return new_sample, inspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:37.060081Z",
     "start_time": "2019-06-28T08:41:37.044449Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_shap_dendogram(inspector: ModelInspector) -> None:\n",
    "    \"\"\"Plot dendogram of the shape clustering.\"\"\"\n",
    "    M = inspector.shap_matrix()\n",
    "    number_features = inspector.predictor.sample.features.shape[1]\n",
    "    linkage_tree = inspector.cluster_dependent_features()\n",
    "    ax = plt.figure(figsize=(10,number_features*.5)).add_subplot(111)\n",
    "    style = FeatMapStyle(ax)\n",
    "    DendrogramDrawer(title=TARGET, linkage_tree=linkage_tree, style=style).draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap culstering iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:37.075701Z",
     "start_time": "2019-06-28T08:41:37.060081Z"
    }
   },
   "outputs": [],
   "source": [
    "black_list1 = ['WoodDeckSF', \n",
    "               #'BsmtFinSF1', \n",
    "               \"OpenPorchSF\",\n",
    "               \"MSSubClass\",\n",
    "               \"KitchenAbvGr\",\n",
    "               'BsmtUnfSF', \n",
    "               #'MasVnrArea',\n",
    "               'LotFrontage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:41:52.644930Z",
     "start_time": "2019-06-28T08:41:37.075701Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample1, inspector1 = shap_clustering_iteration(sample, black_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:42:12.415983Z",
     "start_time": "2019-06-28T08:41:52.644930Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_shap_dendogram(inspector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap clustering iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:42:12.431566Z",
     "start_time": "2019-06-28T08:42:12.415983Z"
    }
   },
   "outputs": [],
   "source": [
    "black_list2 = [\n",
    "    \"YearRemodAdd\",\n",
    "    \"OverallCond\",\n",
    "    \"2ndFlrSF\",\n",
    "    #\"MSSubClass\",\n",
    "    #\"KitchenAbvGr\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:42:26.897794Z",
     "start_time": "2019-06-28T08:42:12.431566Z"
    }
   },
   "outputs": [],
   "source": [
    "sample2, inspector2 = shap_clustering_iteration(sample1, black_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:42:47.396826Z",
     "start_time": "2019-06-28T08:42:26.897794Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_shap_dendogram(inspector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:42:47.412456Z",
     "start_time": "2019-06-28T08:42:47.396826Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor = inspector2.predictor\n",
    "sim = UnivariateSimulation(predictor=predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T08:42:47.459329Z",
     "start_time": "2019-06-28T08:42:47.412456Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "dd = widgets.Dropdown(\n",
    "    options=predictor.sample.features.columns,\n",
    "    description='Feature:',\n",
    "    disabled=False,\n",
    "    layout={\"width\":\"550px\"}\n",
    ")\n",
    "\n",
    "btn = widgets.Button(description='Simulate')\n",
    "\n",
    "def plot_simulation(feature:str):\n",
    "    yield_change = sim.simulate_yield_change(\n",
    "            parameterized_feature=feature,\n",
    "            parameter_values=UnivariateSimulation.observed_feature_values(\n",
    "                feature_name=feature,\n",
    "                sample=predictor.sample,\n",
    "                min_relative_frequency=0.03,\n",
    "                limit_observations=100\n",
    "            ),\n",
    "    )\n",
    "    \n",
    "    yield_change_aggr = UnivariateSimulation.aggregate_simulated_yield_change(\n",
    "                    results_per_split=yield_change, percentiles=[10, 50, 90])\n",
    "    \n",
    "    XLABEL_TITLE = f\"{feature}\"\n",
    "    YLABEL_TITLE = f\"Predicted mean yield uplift ({TARGET})\"\n",
    "    COLOR1 = 'red'\n",
    "    COLOR2 = 'silver'\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10,10), sharex=True)\n",
    "    \n",
    "    # plot lines of prediction\n",
    "    ax1.set_xlabel(XLABEL_TITLE, color='black', labelpad=10, fontsize=12)\n",
    "    ax1.set_ylabel(YLABEL_TITLE, color='black', fontsize=12)\n",
    "    line1, = ax1.plot(yield_change_aggr.index, yield_change_aggr.iloc[:,0], color=COLOR2, linewidth=1)\n",
    "    line2, = ax1.plot(yield_change_aggr.index, yield_change_aggr.iloc[:,1], color=COLOR1)\n",
    "    line3, = ax1.plot(yield_change_aggr.index, yield_change_aggr.iloc[:,2], color=COLOR2, linewidth=1)\n",
    "    ax1.axhline(y=0, color='black', linewidth=.5)\n",
    "    ax1.tick_params(axis='x', labelcolor='black')\n",
    "    for pos in ['top', 'right', 'bottom']:\n",
    "        ax1.spines[pos].set_visible(False)\n",
    "    ax1.tick_params(axis='x', labelbottom=True, bottom=False)\n",
    "    ax1.legend((line3, line2, line1), ('90th percentile', 'Median', '10th percentile'), frameon=False)\n",
    "    \n",
    "    # plot the histogram\n",
    "    x = sample.features[feature].dropna()\n",
    "    hist_range = (min(yield_change_aggr.index), max(yield_change_aggr.index))\n",
    "    n, bins, patches = ax2.hist(x, edgecolor='white', color=COLOR2, range=hist_range)\n",
    "    bins1 = pd.Series(bins).rolling(window=2).mean().shift(-1).dropna()\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    max_y = max(n)\n",
    "    y_offset = max_y * 0.05\n",
    "    for (x,y) in zip(bins1, n):\n",
    "        if y>0:\n",
    "            ax2.text(x, y + y_offset, str(int(y)), color='black', horizontalalignment='center')\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    for pos in ['top', 'right', 'left', 'bottom']:\n",
    "        ax2.spines[pos].set_visible(False)\n",
    "    plt.subplots_adjust(hspace=.2)\n",
    "    plt.show()\n",
    "\n",
    "def on_click(btn):\n",
    "    clear_output()\n",
    "    display(widgets.HBox([dd, btn]))\n",
    "    plot_simulation(feature=dd.value)\n",
    "    \n",
    "btn.on_click(on_click)    \n",
    "display(widgets.HBox([dd, btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "688px",
    "left": "97px",
    "top": "110.233px",
    "width": "229.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
