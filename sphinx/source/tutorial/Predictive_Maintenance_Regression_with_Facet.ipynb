{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<img src=\"../_static/Gamma_Facet_Logo_RGB_LB.svg\" width=\"500\" style=\"padding-bottom: 70px; padding-top: 70px; margin: auto; display: block\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with FACET\n",
    "\n",
    "***\n",
    "\n",
    "**Robust and impactful Data Science with FACET**\n",
    "\n",
    "FACET enables us to perform a number of critical steps in best practice Data Science work flow easily, efficiently and reproducibly:\n",
    "\n",
    "1. Create a robust pipeline for learner selection using LearnerRanker and enabling the use of bootstrap cross-validation.\n",
    "\n",
    "2. Enhance our model inspection to understand drivers of predictions using local explanations of features via SHAP values by applying a novel methodology that decomposes SHAP values into measures of synergy, redundancy, and independence between each pair of features.\n",
    "\n",
    "3. Quickly apply historical simulation to gain key insights into feature values that minimize or maximize the predicted outcome.\n",
    "\n",
    "***\n",
    "\n",
    "**Context**\n",
    "\n",
    "The data are from simulated experiments of a naval vessel (Frigate) Gas Turbine (GT) propulsion plant. The simulator considers the performance decay over time of the GT components such as GT compressor and turbines. One observation in this dataset represents the current decay states of the compressor and the gas turbine along with several sensor readings of the vessel at that point in time. The decay state is a performance metric [0, 1] where 1 means delivering 100% of nominal performance. We want to determine the machine settings which maximize the gas turbine decay state coefficient.\n",
    "\n",
    "Utilizing FACET we will: \n",
    "\n",
    "1. Predict the decay state of the gas turbine as accurately as possible\n",
    "2. Understand which parameters drive the decay state of the turbine\n",
    "3. Analyze how these drivers interact with each other and the target\n",
    "\n",
    "While we can solve questions 1 and parts of question 2 with commonly used machine learning packages, `facet` will enable us to make better inferences about the way some of the features share or complement information and help us to figure out the optimal settings of the vessel to minimize the equipment degradation at a variety of ship speeds.\n",
    "\n",
    "***\n",
    "\n",
    "**Tutorial outline**\n",
    "\n",
    "1. [Preprocessing and initial feature selection](#Preprocessing-and-initial-feature-selection)\n",
    "2. [Selecting a learner using FACET ranker](#Selecting-a-learner-using-FACET-ranker)\n",
    "3. [Using the FACET inspector for model inspection](#Using-the-FACET-inspector-for-model-inspection)\n",
    "4. [FACET univariate simulator: the impact of waist to height ratio](#FACET-univariate-simulator:-the-impact-of-waist-to-height-ratio)\n",
    "5. [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:29:36.416582Z",
     "start_time": "2020-08-28T14:29:36.410164Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# This cell is only required as long as the `facet` package is not public yet\n",
    "\n",
    "# this cell's metadata contains\n",
    "# \"nbsphinx\": \"hidden\" so it is hidden by nbsphinx\n",
    "\n",
    "def _set_paths() -> None:\n",
    "    # set the correct path when launched from within PyCharm\n",
    "\n",
    "    module_paths = [\"pytools\", \"facet\", \"sklearndf\"]\n",
    "\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    if 'cwd' not in globals():\n",
    "        # noinspection PyGlobalUndefined\n",
    "        global cwd\n",
    "        cwd = os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir)\n",
    "        os.chdir(cwd)   \n",
    "    print(f\"working dir is '{os.getcwd()}'\")\n",
    "    for module_path in module_paths:\n",
    "        if module_path not in sys.path:\n",
    "            sys.path.insert(0, os.path.abspath(f\"{cwd}/{os.pardir}/{module_path}/src\"))\n",
    "        print(f\"added `{sys.path[0]}` to python paths\")\n",
    "        \n",
    "def _ignore_warnings():\n",
    "    # ignore irrelevant warnings that would affect the output of this tutorial notebook\n",
    "    \n",
    "    # ignore a useless LGBM warning\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, message=r\".*Xcode_8\\.3\\.3\")\n",
    "\n",
    "_set_paths()\n",
    "_ignore_warnings()\n",
    "\n",
    "del _set_paths, _ignore_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:29:36.537625Z",
     "start_time": "2020-08-28T14:29:36.419137Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# this cell's metadata contains\n",
    "# \"nbsphinx\": \"hidden\" so it is hidden by nbsphinx\n",
    "\n",
    "def _configure_matplotlib():\n",
    "    # set global options for matplotlib\n",
    "    \n",
    "    import matplotlib\n",
    "    \n",
    "    matplotlib.rcParams['figure.figsize'] = (16.0, 8.0)\n",
    "    matplotlib.rcParams['figure.dpi'] = 72\n",
    "\n",
    "_configure_matplotlib()\n",
    "\n",
    "del _configure_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TL;DR"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    },
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "- :class:`facet.Sample` wraps the features and the target\n",
    "- :class:`facet.inspection.LearnerInspector` helps explaining what a learner (regressor or classifier) has learnt\n",
    "- :class:`facet.selection.LearnerRanker` helps ranking different models and hyperparameter configurations in a pipeline\n",
    "- :class:`facet.validation.BootStrapCV` generates cross-validation splits by random sampling with replacement\n",
    "- :class:`facet.simulation.partition.ConitnuousRangePartitioner` Selects relevant partitioning of values of a feature to be simulated\n",
    "- :class:`facet.simulation.UnivariateUpliftSimulator` identifies values of a feature that maximize or minimize the target variable\n",
    "- :class:`facet.simulation.viz.SimulationDrawer` visualizes simulation results in an informative chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-27T13:10:25.031514Z",
     "start_time": "2020-08-27T13:10:25.029576Z"
    }
   },
   "source": [
    "# Required Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook, we will import not only the `facet` package, but also a number of other packages useful to solve this task. Overall, we can break down the imports into three categories: \n",
    "1. Common packages (pandas, matplotlib, etc.)\n",
    "2. Required `facet` classes (inpsection, selection, validation, simulation, etc.)\n",
    "3. Other `gamma` packages which simplify pipelining with `sklearn` and provide some visualization utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:29:37.518624Z",
     "start_time": "2020-08-28T14:29:36.540501Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma Facet imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:29:38.013412Z",
     "start_time": "2020-08-28T14:29:37.520802Z"
    }
   },
   "outputs": [],
   "source": [
    "from facet import Sample\n",
    "from facet.inspection import LearnerInspector\n",
    "from facet.selection import LearnerRanker, LearnerGrid\n",
    "from facet.validation import BootstrapCV\n",
    "from facet.simulation.partition import ContinuousRangePartitioner\n",
    "from facet.simulation import UnivariateUpliftSimulator\n",
    "from facet.simulation.viz import SimulationDrawer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T14:15:20.686543Z",
     "start_time": "2020-08-18T14:15:20.683573Z"
    }
   },
   "source": [
    "Sklearndf imports\n",
    "\n",
    "Instead of using the \"regular\" scikit-learn package, we are using the `sklearndf` (see on [GitHub](https://github.com/orgs/BCG-Gamma/sklearndf/)) wrapper which keeps metadata such as column names when passing the data through the scikit-learn learners.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:29:38.175010Z",
     "start_time": "2020-08-28T14:29:38.014809Z"
    }
   },
   "outputs": [],
   "source": [
    "# sklearndf\n",
    "from sklearndf.pipeline import PipelineDF, RegressorPipelineDF\n",
    "from sklearndf.regression import RandomForestRegressorDF\n",
    "from sklearndf.regression.extra import LGBMRegressorDF\n",
    "from sklearndf.transformation.extra import BorutaDF\n",
    "from sklearndf.transformation import SimpleImputerDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:29:38.184383Z",
     "start_time": "2020-08-28T14:29:38.176913Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytools.viz.dendrogram import DendrogramDrawer, DendrogramReportStyle\n",
    "from pytools.viz.distribution import ECDFDrawer\n",
    "from pytools.viz.matrix import MatrixDrawer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T10:40:59.547062Z",
     "start_time": "2020-08-05T10:40:59.544794Z"
    }
   },
   "source": [
    "# Preprocessing and initial feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load our turbine decay data and create a simple preprocessing pipeline. For those interested initial EDA can be found in the Appendix [Exploratory Data Analysis](#Exploratory-Data-Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the prepared dataframe\n",
    "decay_df = pd.read_csv(\"sphinx/source/tutorial/gas_turbine_data.txt\", delim_whitespace=True)\n",
    "\n",
    "# assign human-readable labels\n",
    "decay_df.columns = [\n",
    "    'Lever Position',\n",
    "    'Ship Speed', \n",
    "    'Turbine Shaft Torque (kN m)', \n",
    "    'Turbine Rate of Revolutions (rpm)', \n",
    "    'Generator Rate of Revolutions (rpm)', \n",
    "    'Starboard Propeller Torque (kN)', \n",
    "    'Port Propeller Torque (kN)', \n",
    "    'HP Turbine exit temp (C)', \n",
    "    'GT Compressor inlet air temp (C)', \n",
    "    'GT Compressor outlet air temp (C)', \n",
    "    'Turbine exit pressure (bar)', \n",
    "    'Compressor inlet air pressure (bar)', \n",
    "    'Compressor outlet air pressure (bar)', \n",
    "    'Turbine exhaust gas pressure (bar)', \n",
    "    'Turbine injection control', \n",
    "    'Fuel flow', \n",
    "    'GT Compressor decay state coeff',  \n",
    "    'GT Turbine decay state coeff']\n",
    "\n",
    "# need to drop the other target\n",
    "decay_df.drop(\"GT Compressor decay state coeff\", inplace=True, axis=1)\n",
    "\n",
    "# have a look\n",
    "decay_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easier management of the data we are using in this example, we are using FACET's `Sample` class, which allows to do a number of things: \n",
    "\n",
    "- Quickly access the target vs. features\n",
    "- Pass the sample into `sklearndf` data pipelines\n",
    "- Assign weight vectors to the sample which are propagated down to the learners (given that they support sample weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"GT Turbine decay state coeff\"\n",
    "sample = Sample(observations=decay_df, target=TARGET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we should create a minimum preprocessing pipeline. However, based on our EDA ([Exploratory Data Analysis](#Exploratory-Data-Analysis-(EDA))) we have no missing values or a need to manage categorical variables etc. However, while it is not needed we will create a simple imputation preprocessing pipeline using [sklearndf's](https://github.com/BCG-Gamma/sklearndf) `SimpleImputerDF` to demonstrate how such a pipeline is created and included in subsequent analytic steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = PipelineDF(\n",
    "    steps = [\n",
    "        (\"impute\", SimpleImputerDF())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform some initial feature selection using the [Boruta](https://www.jstatsoft.org/article/view/v036i11) algorithm, a smart feature selection method to eliminate features whose predictive power is not better than random noise.\n",
    "\n",
    "The BorutaDF transformer in our [sklearndf](https://github.com/BCG-Gamma/sklearndf) package provides easy access to this powerful method. The approach relies on a tree-based learner, usually a random forest.\n",
    "\n",
    "For the random forest, we rely on default parameters but set the maximum tree depth to 5 (for Boruta, setting a depth between 3 and 7 is highly recommended and depends on the number of features and expected complexity of the feature/target interactions). The number of trees is automatically managed by the Boruta feature selector (argument n_estimators=”auto”).\n",
    "\n",
    "We also use parallelization for the random forest using `n_jobs` to accelerate the Boruta iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Boruta object\n",
    "boruta = BorutaDF(\n",
    "    estimator = RandomForestRegressorDF(max_depth=5, random_state=42, n_jobs=3), \n",
    "    n_estimators=\"auto\", \n",
    "    max_iter=50,\n",
    "    random_state=42, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# combine Boruta with the preprocessing pipeline\n",
    "selection_pipeline = PipelineDF(\n",
    "    steps = [\n",
    "        (\"preprocess\", preprocessing_pipeline),\n",
    "        (\"feature selection\", boruta)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since [sklearndf](https://github.com/BCG-Gamma/sklearndf) closely follows the `scikit-learn` syntax, we can fit this pipeline on the `sample.features` and `sample.target` properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit pipeline and print selected features\n",
    "selection_pipeline.fit(X=sample.features, y=sample.target)\n",
    "print(f\"Selected features: {selection_pipeline.features_out.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-05T10:51:12.659Z"
    }
   },
   "source": [
    "Boruta selected 9 features which we will now keep in our FACET sample object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:32:16.589723Z",
     "start_time": "2020-08-28T14:32:16.585993Z"
    }
   },
   "outputs": [],
   "source": [
    "# update FACET sample object to only those features Boruta identified as useful\n",
    "sample_selected = sample.keep(features=selection_pipeline.features_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting a learner using FACET ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "We will use a simple [bootstrap](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) here as this will give us reliable estimates of our model's accuracy. The `facet.validation` module provides a convenient implementation of this important cross-validation strategy: `facet.validation.BootstrapCV`.  \n",
    "\n",
    "Note that if we were given a time series dataset here (i.e. if we had timestamps of the GT readings) we could use a stationary bootstrap here using `facet.validation.StationaryBootstrapCV`). \n",
    "\n",
    "The bootstrap is an important extension of scikit-learn, as scikit-learn’s native cross-validators do not support sampling with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:32:16.594237Z",
     "start_time": "2020-08-28T14:32:16.591677Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = BootstrapCV(n_splits=10, random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "`sklearndf` and `facet` implement a number of additional useful wrappers which further simplify comparing and tuning a larger number of models and configurations: \n",
    "\n",
    "- `facet.selection.LearnerGrid`: allows to pass a Regressor pipeline and a set of hyperparameters\n",
    "- `facet.selection.LearnerRanker`: multiple `LearnerGrid`s can be passed into the this class as a list - this allows tuning hyperparameters both across different types of learners in a single step and ranks the resulting models accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:32:16.599454Z",
     "start_time": "2020-08-28T14:32:16.596341Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipeline = RegressorPipelineDF(\n",
    "    regressor=RandomForestRegressorDF(n_estimators=500, random_state=42),\n",
    ")\n",
    "\n",
    "lgbm_pipeline = RegressorPipelineDF(\n",
    "    regressor=LGBMRegressorDF(random_state=42),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, we want to tune two sets of hyperparameters for each learner and cross-validate them using the Bootstrap method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:32:16.606273Z",
     "start_time": "2020-08-28T14:32:16.601757Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = [\n",
    "    LearnerGrid(\n",
    "        pipeline=rf_pipeline, \n",
    "        learner_parameters={ \n",
    "            \"min_samples_leaf\": [8, 16], \n",
    "            \"n_estimators\": [20, 50, 100]\n",
    "        } \n",
    "        ),\n",
    "    LearnerGrid(\n",
    "        pipeline=lgbm_pipeline, \n",
    "        learner_parameters={ \n",
    "            \"min_data_in_leaf\": [8, 16], \n",
    "            \"subsample\": [0.8, 1], \n",
    "            \"boosting_type\": [\"gbdt\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We now fit the `grid` defined above using the `facet.selection.LeanerRanker`, which will run a gridsearch (or random search if defined) using the bootstrapped cross-validation on our selected set of features from Boruta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:33:24.495845Z",
     "start_time": "2020-08-28T14:32:16.609006Z"
    }
   },
   "outputs": [],
   "source": [
    "ranker = LearnerRanker(\n",
    "    grids=grid,\n",
    "    cv=cv,\n",
    "    n_jobs=-3\n",
    ").fit(sample=sample_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T11:28:17.762068Z",
     "start_time": "2020-08-28T11:28:17.756762Z"
    }
   },
   "source": [
    "We can see how each model scored using the `summary_report()` method of the `LearnerRanker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:33:24.504903Z",
     "start_time": "2020-08-28T14:33:24.499039Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at the top 5 models\n",
    "print(ranker.summary_report(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T11:42:06.425585Z",
     "start_time": "2020-08-05T11:42:06.423740Z"
    }
   },
   "source": [
    "# Using the FACET inspector for model inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP decomposition of features is a method we developed to identify pairs of features that share, or re-use information to predict the target. We distinguish two cases:\n",
    "\n",
    "- **Synergy**: the degree to which two features jointly contribute to the prediction by combining information. For example, given features X and Y as coordinates on a chess board, the colour of a square can only be predicted when considering X and Y in combination\n",
    "\n",
    "\n",
    "- **Redundancy**: the degree to which two features use the same information, independently of each other, to contribute to a prediction. For example, temperature and pressure in a pressure cooker are redundant features for predicting cooking time since pressure will rise relative to the temperature, and vice versa. Therefore knowing just one of either temperature or pressure will likely enable the same predictive accuracy.\n",
    "\n",
    "Both cases can apply at the same time, i.e. a pair of features can use some information synergistically while using other information redundantly.\n",
    "\n",
    "To analyse redundancy for all possible feature parings, the approach is:\n",
    "\n",
    "1. Calculate the feature redundancy matrix using SHAP value decomposition - this gives us pairwise redundancy between features, in the range of 0.0 (fully unique contributions) and 1.0 (fully redundant contributions)\n",
    "\n",
    "2. Transform the feature redundancy matrix into a feature distance matrix, where distance is expressed as (1.0 - redundancy)\n",
    "\n",
    "3. Perform hierarchical, single-linkage clustering on the distance matrix, thus identifying groups of low-distance, redundant features which activate “in tandem” to predict the outcome\n",
    "\n",
    "The same approach can be used to analyse synergy.\n",
    "\n",
    "The inspector can calculate all of this with a single method call, but also offers methods to access the intermediate results of each step. A lightweight visualization framework is available to render the results in different styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:39:19.910709Z",
     "start_time": "2020-08-28T14:33:24.517489Z"
    }
   },
   "outputs": [],
   "source": [
    "inspector = LearnerInspector()\n",
    "inspector.fit(crossfit=ranker.best_model_crossfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T13:12:54.363503Z",
     "start_time": "2020-08-05T13:12:54.360977Z"
    }
   },
   "source": [
    "## Synergy and redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:08:11.655421Z",
     "start_time": "2020-08-28T16:08:11.057362Z"
    }
   },
   "outputs": [],
   "source": [
    "# synergy heatmaps\n",
    "synergy_matrix = inspector.feature_synergy_matrix()\n",
    "MatrixDrawer(style=\"matplot%\").draw(synergy_matrix, title=\"Feature synergies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the synergy matrix that the feature \"Compressor outlet air pressure (bar)\" is highly synergystic with other features. This means that the outlet air pressure **in combination** with the turbine torque, rate of revolutions and generator rate of revolutions carries a lot of information for the model. It should not be surprising that this feature also as the highest mean absolute SHAP score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this uncovers very high redundancy which would not have been visible in a simple correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:08:39.064822Z",
     "start_time": "2020-08-28T16:08:38.477297Z"
    }
   },
   "outputs": [],
   "source": [
    "# redundancy heatmap\n",
    "redundancy_matrix = inspector.feature_redundancy_matrix()\n",
    "MatrixDrawer(style=\"matplot%\").draw(redundancy_matrix, title=\"Feature redundancies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:17:34.674348Z",
     "start_time": "2020-08-28T16:17:34.279844Z"
    }
   },
   "outputs": [],
   "source": [
    "# redundancy dendrogram\n",
    "redundancy = inspector.feature_redundancy_linkage()\n",
    "DendrogramDrawer().draw(title=\"Redundancy linkage\", data=redundancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience when working in a non-notebook environment, all of the `Drawer`s provided by the [pytools](https://github.com/BCG-Gamma/pytools) package also support a `style='text'` flag.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:25:17.524926Z",
     "start_time": "2020-08-28T16:25:17.520341Z"
    }
   },
   "outputs": [],
   "source": [
    "DendrogramDrawer(style=\"text\").draw(title=\"Redundancy linkage\", data=redundancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T14:39:21.951535Z",
     "start_time": "2020-08-28T14:39:21.949456Z"
    }
   },
   "outputs": [],
   "source": [
    "redundant_features = [\"Fuel flow\", \"Turbine exhaust gas pressure\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the hierarchical clustering, we calculate a linkage tree and plug it into a dendrogram drawer. This makes it easy to visually single out features that are both important and mutually redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we learn from the above? \n",
    "\n",
    "\n",
    "**Synergy**\n",
    "We can see in the synergy matrix that the feature \"Compressor outlet air pressure (bar)\" is highly synergystic with other features. This means that the outlet air pressure **in combination** with the turbine torque, rate of revolutions and generator rate of revolutions carries a lot of information for the model. It should not be surprising that this feature also as the highest mean absolute SHAP score. \n",
    "\n",
    "When simulating the data, we should look at these features first in order to figure out which feature maximized the decay state coefficient. \n",
    "\n",
    "**Redundancy**\n",
    "The redundancy matrix and dendrogram reveals a \"cluster\" of two variables which are highly redundant - Turbine injection control and Fuel flow. That is, they provide the same information to the target and are likely dependent on each other. Looking at the process, the fuel flow is a consequence from the turbine injection control, so we can remove this redundant feature. \n",
    "\n",
    "It is important to remove redundant features before running the simulation. As we simulate single features along their historical partition while keeping all other observations the same, we risk creating adversing signals when the model makes a prediction about the target if we simulate one feature, but don't change the feature it shares information with alongside. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In turn, we remove the redundant features from the sample and create a revised sample on which we re-train the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:20:15.706573Z",
     "start_time": "2020-08-28T16:20:15.702905Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_revised = sample_selected.drop(redundant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:21:09.099135Z",
     "start_time": "2020-08-28T16:20:16.527678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run the training pipeline again\n",
    "ranker_revised = LearnerRanker( \n",
    "    grids=grid, cv=cv, n_jobs=-3\n",
    ").fit(sample=sample_revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:21:09.113777Z",
     "start_time": "2020-08-28T16:21:09.103236Z"
    }
   },
   "outputs": [],
   "source": [
    "ranker_revised.best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACET univariate simulator: the impact of compressor outlet air temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T15:56:26.709687Z",
     "start_time": "2020-08-07T15:56:26.682253Z"
    }
   },
   "source": [
    "Another advantage of FACET is the ability to quickly instigate and run univariate simulation. From the synergy matrix, we can see that the Compressor outlet temperature has the highest synergy with most other features. Therefore, we want to see how the target behaves if we simulate this feature such that each state had a constant outlet compressor temperature.\n",
    "\n",
    "The absolute SHAP values also confirm that the three features most synergistic with `GT Compressor outlet air temp (C)` are also the most important features according to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:30:48.931395Z",
     "start_time": "2020-08-28T16:30:48.866357Z"
    }
   },
   "outputs": [],
   "source": [
    "abs_shap_values = inspector.shap_values().abs().sum(axis=0).reset_index().rename({0: \"Sum of abs SHAP values\"}, axis=1)\n",
    "abs_shap_values.sort_values(by=\"Sum of abs SHAP values\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the basis for the simulation, we divide the feature into relevant partitions: \n",
    "\n",
    "- We use the `facet.simulation.partition.ContinuousRangePartitioner` to split the range of observed values of the outlet air temperature into intervals of equal size. Each partition is represented by the central value of that partition. \n",
    "- For each partition, the simulator creates an artificial copy of the original sample assuming the variable to be simulated has the same value across all observations - which is the value representing the partition. Using the best LearnerCrossfit acquired from the ranker, the simulator now re-predicts all targets using the models trained for all folds, and determines the average uplift of the target variable resulting from this.\n",
    "- The `facet.simulation.viz.SimulationDrawer` visualized the result; both in a matplotlib and a plain-text style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:21:41.500250Z",
     "start_time": "2020-08-28T16:21:41.498208Z"
    }
   },
   "outputs": [],
   "source": [
    "# set-up and run a simulation\n",
    "SIM_FEATURE = 'GT Compressor outlet air temp (C)'\n",
    "simulator = UnivariateUpliftSimulator(crossfit=ranker.best_model_crossfit, n_jobs=3)\n",
    "partitioner = ContinuousRangePartitioner()\n",
    "univariate_simulation = simulator.simulate_feature(name=SIM_FEATURE, partitioner=partitioner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T16:21:09.250184Z",
     "start_time": "2020-08-28T16:21:09.246001Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the results\n",
    "SimulationDrawer().draw(data=univariate_simulation, title=SIM_FEATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also get a print out of simulation results\n",
    "SimulationDrawer(\"text\").draw(data=univariate_simulation, title=SIM_FEATURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this that the turbine decay state coefficient is maximized when the outlet air temperature of the gas turbine is as small as possible. Note that this is only looking at the partitions of the historically observed range, as extrapolating these predictions into unobserved regions would risk creating infeasible scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "The dataset used in this example is available on [Kaggle](https://www.kaggle.com/elikplim/maintenance-of-naval-propulsion-plants-data-set) and contains data from experiments carried out by means of a numerical simulator of a naval vessel (Frigate) characterized by a **Gas Turbine propulsion plant**. In this release of the simulator it is also possible to take into account the performance decay over time of the GT components such as GT compressor and turbines.\n",
    "\n",
    "Each possible degradation state of the plant can be characterized by three parameters: \n",
    "\n",
    "- Ship speed (linear function of the lever position)\n",
    "- Compressor degradation coefficient kMc\n",
    "- Turbine degradation coefficient\n",
    "\n",
    "The degradation coefficients typically vary between [1; 0.95] for compressor and [1; 0.975] for the gas turbine. \n",
    "\n",
    "**Features**\n",
    "\n",
    "One observation in this dataset represents the current decay states of the compresor and the gas turbine along with a number of sensor readings of the shipping vessels at that point in time. \n",
    "\n",
    "Our target, the Gas Turbine decay  state is being modelled as a performance decay state metric which is measured as 1 to 0, 1 meaning delivering 100% of the nominal performance. Therefore, we want to determine the machine settings which **maximize the gas turbine decay state coefficient**. \n",
    "\n",
    "\n",
    "**Learning Problem**\n",
    "\n",
    "For this learning problem, we have three key objectives: \n",
    "\n",
    "1. Predict the decay state of the gas turbine as accurately as possible\n",
    "2. Understand which parameters drive the decay state of the turbine\n",
    "3. Analyze how these drivers interact with each other and the target\n",
    "\n",
    "\n",
    "While we can solve questions 1 and parts of question 2 with commonly used machine learning packages, `facet` will enable us to make better inferences about the way some of the features share or complement information and help us to figure out the optimal settings of the vessel to minimize the equipment degradation at a variety of ship speeds.\n",
    "\n",
    "Reference for the dataset used in this example is: A. Coraddu, L. Oneto, A. Ghio, S. Savio, D. Anguita, M. Figari, Machine Learning Approaches for Improving Condition?Based Maintenance of Naval Propulsion Plants, Journal of Engineering for the Maritime Environment, 2014, DOI: 10.1177/1475090214540874, (In Press)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sphinx/source/tutorial/gas_turbine_data.txt\", delim_whitespace=True)\n",
    "\n",
    "df.columns = ['Lever Position', \n",
    "              'Ship Speed', \n",
    "              'Turbine Shaft Torque (kN m)', \n",
    "              'Turbine Rate of Revolutions (rpm)', \n",
    "              'Generator Rate of Revolutions (rpm)', \n",
    "              'Starboard Propeller Torque (kN)', \n",
    "              'Port Propeller Torque (kN)', \n",
    "              'HP Turbine exit temp (C)', \n",
    "              'GT Compressor inlet air temp (C)', \n",
    "              'GT Compressor outlet air temp (C)', \n",
    "              'Turbine exit pressure (bar)', \n",
    "              'Compressor inlet air pressure (bar)', \n",
    "              'Compressor outlet air pressure (bar)', \n",
    "              'Turbine exhaust gas pressure (bar)', \n",
    "              'Turbine injection control', \n",
    "              'Fuel flow', \n",
    "              'GT Compressor decay state coeff',  \n",
    "              'GT Turbine decay state coeff']\n",
    "\n",
    "TARGET = \"GT Turbine decay state coeff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to drop the other target\n",
    "df.drop(\"GT Compressor decay state coeff\", inplace=True, axis=1)\n",
    "sample = Sample(observations=df, target=TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also quickly check for missing values, although we can see that there appears to be none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missing by feature\n",
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pytool's `ECDFDrawer()` to draw the cumulative distribution of the target. This shows us that the target is uniformly distributed in increments of 0.001 increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the target distribution\n",
    "ECDFDrawer().draw(sample.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at feature distributions and correlations\n",
    "sns.pairplot(sample.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick EDA summary:**\n",
    "\n",
    "- We have no missing values in our data\n",
    "- We are dealing with a linearly distributed target\n",
    "- The features exhibit a mixture of linear and non-linear relationships amongst each other. This gives us reason to test a number of non-parametric models and compare their performance. \n",
    "- Some features appear to be constant and should therefore be filtered out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
