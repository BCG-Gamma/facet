{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.082998Z",
     "start_time": "2020-09-08T20:43:40.170617Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.099017Z",
     "start_time": "2020-09-08T20:43:41.084640Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_sim(n=100,\n",
    "             intercept=-5,\n",
    "             linear_vars=10,\n",
    "             noise_vars=0,\n",
    "             corr_vars=0,\n",
    "             corr_type=\"AR1\",\n",
    "             corr_value=0,\n",
    "             mislabel=0,\n",
    "             surg_err=0.05,\n",
    "             bin_var_p=0,\n",
    "             bin_coef=0,\n",
    "             outcome=\"classification\",\n",
    "             regression_err=None,\n",
    "             ):\n",
    "    \"\"\"\n",
    "    This function is for the most part a direct translation of the twoClassSim function from the R package caret.\n",
    "    Full credit for the approach used for simulating binary classification data foes to the Authors and contributors\n",
    "    of caret.\n",
    "\n",
    "    There are some modifications from the R implementation:\n",
    "    1. The ordinal outcome option has not been translated\n",
    "    2. The addition of another linear feature that is a copy of another used in the linear predictor with a small amount\n",
    "    of noise has been added to allow for the study of variable surrogacy\n",
    "    3. Option for a binary predictor and surrogate has also been added\n",
    "    4. Toggle option for regression versus classification has also been added\n",
    "\n",
    "    Source:\n",
    "        Caret: Kuhn, M. (2008). Caret package. Journal of Statistical Software, 28(5)\n",
    "        https://rdrr.io/cran/caret/man/twoClassSim.html\n",
    "\n",
    "    :param n: number of observations\n",
    "    :param intercept: value for the intercept which can be modified to generate class imbalance\n",
    "    :param linear_vars: number of linear features\n",
    "    :param noise_vars: number of noise features (i.e., do not contribute to the linear predictor)\n",
    "    :param corr_vars: number of correlated noise features\n",
    "    :param corr_type: type of correlation (exchangeable or auto-regressive) for correlated noise features\n",
    "    :param corr_value: correlation for correlated noise features\n",
    "    :param mislabel: proportion of mis-labelling of target if required\n",
    "    :param surg_err: degree of noise added to first linear predictor\n",
    "    :param bin_var_p: prevalence for a binary feature to include in linear predictor\n",
    "    :param bin_coef: coefficient for the impact of binary feature on linear predictor\n",
    "    :param outcome: can be either classification for a binary outcome or regression for a continuous outcome\n",
    "    :param regression_err: the error to be used in simulating a regression outcome\n",
    "    :return: data frame containing the simulated features and target for classification\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(seed=4763546)\n",
    "\n",
    "    # add two correlated normal features\n",
    "    sigma = np.array([[2, 1.3], [1.3, 2]])\n",
    "    mu = [0, 0]\n",
    "    tmp_data = pd.DataFrame(np.random.multivariate_normal(mu, sigma, size=n), columns=[\"TwoFactor1\", \"TwoFactor2\"])\n",
    "\n",
    "    # add linear features\n",
    "    if linear_vars > 0:\n",
    "        lin_cols = ['Linear' + str(x) for x in range(1, linear_vars + 1)]\n",
    "        tmp_data = pd.concat([tmp_data, pd.DataFrame(np.random.normal(size=(n, linear_vars)), columns=lin_cols)],\n",
    "                             axis=1)\n",
    "\n",
    "    # add features for non-linear terms\n",
    "    tmp_data['Nonlinear1'] = pd.Series(np.random.uniform(low=-1.0, high=1.0, size=n))\n",
    "    tmp_data = pd.concat([tmp_data, pd.DataFrame(np.random.uniform(size=(n, 2)), columns=['Nonlinear2', 'Nonlinear3'])],\n",
    "                         axis=1)\n",
    "\n",
    "    # add noise variables as needed\n",
    "    if noise_vars > 0:\n",
    "        noise_cols = ['Noise' + str(x) for x in range(1, noise_vars + 1)]\n",
    "        tmp_data = pd.concat([tmp_data, pd.DataFrame(np.random.normal(size=(n, noise_vars)), columns=noise_cols)],\n",
    "                             axis=1)\n",
    "\n",
    "    # add correlated noise features\n",
    "    if corr_vars > 0:\n",
    "        if corr_type == \"exch\":\n",
    "            vc = corr_value * np.ones((corr_vars, corr_vars))\n",
    "            np.fill_diagonal(vc, 1)\n",
    "\n",
    "        elif corr_type == \"AR1\":\n",
    "            vc_values = corr_value ** np.arange(corr_vars)\n",
    "            vc = toeplitz(vc_values)\n",
    "\n",
    "        corr_cols = ['Corr' + str(x) for x in range(1, corr_vars + 1)]\n",
    "        tmp_data = pd.concat([tmp_data,\n",
    "                              pd.DataFrame(np.random.multivariate_normal(np.zeros(corr_vars), vc, size=n),\n",
    "                                           columns=corr_cols)],\n",
    "                             axis=1)\n",
    "\n",
    "    # add a surrogate linear feature\n",
    "    if linear_vars > 0:\n",
    "        tmp_data['Linear1_prime'] = tmp_data['Linear1'] + np.random.normal(0, surg_err, size=n)\n",
    "\n",
    "    # add a binary feature\n",
    "    if bin_var_p > 0:\n",
    "        tmp_data['Binary1'] = np.where(np.random.uniform(size=n) <= bin_var_p, 0, 1)\n",
    "\n",
    "    # generate contributions to linear predictor 4, 4, 2\n",
    "    lp = intercept + 4 * tmp_data.TwoFactor1 + 4 * tmp_data.TwoFactor2 + 2 * tmp_data.TwoFactor1 * tmp_data.TwoFactor2 \\\n",
    "         + tmp_data.Nonlinear1 ** 3 + 2 * np.exp(-6 * (tmp_data.Nonlinear1 - 0.3) ** 2) + \\\n",
    "         2 * np.sin(np.pi * tmp_data.Nonlinear2 * tmp_data.Nonlinear3)\n",
    "        \n",
    "\n",
    "    if linear_vars > 0:\n",
    "        lin_coeff = np.linspace(10, 1, num=linear_vars) / 4\n",
    "        neg_idx = [_ for _ in range(1, linear_vars, 2)]\n",
    "        lin_coeff[neg_idx] = lin_coeff[neg_idx] * -1\n",
    "        lp = lp + tmp_data[lin_cols].dot(lin_coeff)\n",
    "\n",
    "    if bin_var_p > 0:\n",
    "        lp = lp + bin_coef * tmp_data['Binary1']\n",
    "        tmp_data['Binary1_prime'] = 1 - tmp_data['Binary1']\n",
    "\n",
    "    if outcome == 'classification':\n",
    "\n",
    "        # convert to a probability\n",
    "        prob = 1 / (1 + np.exp(-lp))\n",
    "\n",
    "        # add mislabelling if desired - TO DO: need to fix\n",
    "        if (mislabel > 0) and (mislabel < 1):\n",
    "            shuffle_rows = np.random.choice(n, np.floor(n * mislabel), replace=False)\n",
    "            prob[shuffle_rows] = 1 - prob[shuffle_rows]\n",
    "\n",
    "        # generate target\n",
    "        tmp_data['target'] = np.where(prob <= np.random.uniform(size=n), 0, 1)\n",
    "\n",
    "    elif outcome == 'regression':\n",
    "\n",
    "        # continuous outcome based on linear predictor\n",
    "        tmp_data['target'] = np.random.normal(lp, regression_err, size=n)\n",
    "\n",
    "    return tmp_data\n",
    "\n",
    "\n",
    "def scale_var(df: pd.DataFrame, \n",
    "              feature_name: str, \n",
    "              min_: Union[int, float] =0, \n",
    "              max_: Union[int, float]=1) -> np.array: \n",
    "    \"\"\"\n",
    "    Takes in a data frame and applies a min-max scaler to given bounds for a single column\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(min_, max_))\n",
    "    scaled_arr = scaler.fit_transform(df[[feature_name]]).reshape(1, -1)[0]\n",
    "    return scaled_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.113934Z",
     "start_time": "2020-09-08T20:43:41.101215Z"
    }
   },
   "outputs": [],
   "source": [
    "df = data_sim(n=500,\n",
    "             intercept=0,\n",
    "             linear_vars=3,\n",
    "             noise_vars=1,\n",
    "             corr_vars=0,\n",
    "             corr_type=\"AR1\",\n",
    "             corr_value=0.4,\n",
    "             mislabel=0,\n",
    "             surg_err=0.05,\n",
    "             bin_var_p=0,\n",
    "             bin_coef=0,\n",
    "             outcome=\"regression\",\n",
    "             regression_err=0.2,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.119348Z",
     "start_time": "2020-09-08T20:43:41.115607Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename({ \n",
    "    \"TwoFactor1\": \"Weight on bit [kg]\", # higher weight --> higher weight will increase risks of danger \n",
    "    \"TwoFactor2\": \"Drill rate [m/s]\", # higher drill rate --> higher drill rate will provide less time for drilling engineers to observe real time data and adjust drilling parameter set up -> leading to a higher risk of incident (but more economic to drill faster)\n",
    "    \"Linear1\": \"Vertical depth of operation [m]\", # lower point of the well\n",
    "    \"Linear1_prime\": \"Bit depth [m]\", # current position of the drilling bit\n",
    "    \"Linear2\": \"Mud density [kg/m3]\", # need to have equal mud and soil density to avoid well collapse (formation falling in well and blocking pipe) or mud loss (mud flowing in the formation)\n",
    "    \"Linear3\": \"Hole diameter [m]\", # Diameter of the hole (diameter diminishes as depth increases)\n",
    "    \"Noise1\": \"Temperature [C]\", # Temperature at the drilling bit \n",
    "    \"target\": \"Failure likelihood (%)\"\n",
    "}, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.148979Z",
     "start_time": "2020-09-08T20:43:41.121208Z"
    }
   },
   "outputs": [],
   "source": [
    "scaling_dict = { \n",
    "    'Weight on bit [kg]': [100, 500], \n",
    "    'Drill rate [m/s]': [0.1, 1],   \n",
    "    'Vertical depth of operation [m]': [0, 1500], \n",
    "    'Mud density [kg/m3]': [0.5, 4],\n",
    "    'Hole diameter [m]': [0.5, 10], \n",
    "    'Temperature [C]': [0, 40], \n",
    "    'Bit depth [m]': [0, 1500], \n",
    "    'Failure likelihood (%)': [0, 100]\n",
    "}\n",
    "\n",
    "for k,v in scaling_dict.items(): \n",
    "    df.loc[:, k] = scale_var(df, k, v[0], v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.168026Z",
     "start_time": "2020-09-08T20:43:41.150514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight on bit [kg]</th>\n",
       "      <th>Drill rate [m/s]</th>\n",
       "      <th>Vertical depth of operation [m]</th>\n",
       "      <th>Mud density [kg/m3]</th>\n",
       "      <th>Hole diameter [m]</th>\n",
       "      <th>Nonlinear1</th>\n",
       "      <th>Nonlinear2</th>\n",
       "      <th>Nonlinear3</th>\n",
       "      <th>Temperature [C]</th>\n",
       "      <th>Bit depth [m]</th>\n",
       "      <th>Failure likelihood (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239.302549</td>\n",
       "      <td>0.660993</td>\n",
       "      <td>886.156784</td>\n",
       "      <td>2.949484</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.030589</td>\n",
       "      <td>0.822986</td>\n",
       "      <td>0.917557</td>\n",
       "      <td>21.582837</td>\n",
       "      <td>902.435896</td>\n",
       "      <td>23.084672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212.767755</td>\n",
       "      <td>0.647397</td>\n",
       "      <td>567.530485</td>\n",
       "      <td>3.338703</td>\n",
       "      <td>4.617729</td>\n",
       "      <td>0.090338</td>\n",
       "      <td>0.741262</td>\n",
       "      <td>0.831136</td>\n",
       "      <td>27.133111</td>\n",
       "      <td>551.297785</td>\n",
       "      <td>16.010499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256.828737</td>\n",
       "      <td>0.441749</td>\n",
       "      <td>1125.905909</td>\n",
       "      <td>2.503559</td>\n",
       "      <td>6.177708</td>\n",
       "      <td>-0.915346</td>\n",
       "      <td>0.149370</td>\n",
       "      <td>0.537270</td>\n",
       "      <td>10.448471</td>\n",
       "      <td>1144.445348</td>\n",
       "      <td>18.217468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230.388689</td>\n",
       "      <td>0.457263</td>\n",
       "      <td>1297.342216</td>\n",
       "      <td>2.137124</td>\n",
       "      <td>6.089012</td>\n",
       "      <td>-0.885661</td>\n",
       "      <td>0.131785</td>\n",
       "      <td>0.941753</td>\n",
       "      <td>18.143884</td>\n",
       "      <td>1309.752689</td>\n",
       "      <td>20.377512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264.516013</td>\n",
       "      <td>0.498232</td>\n",
       "      <td>731.845400</td>\n",
       "      <td>2.531889</td>\n",
       "      <td>5.303489</td>\n",
       "      <td>0.275052</td>\n",
       "      <td>0.447095</td>\n",
       "      <td>0.750145</td>\n",
       "      <td>13.733294</td>\n",
       "      <td>739.591496</td>\n",
       "      <td>21.080085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight on bit [kg]  Drill rate [m/s]  Vertical depth of operation [m]  \\\n",
       "0          239.302549          0.660993                       886.156784   \n",
       "1          212.767755          0.647397                       567.530485   \n",
       "2          256.828737          0.441749                      1125.905909   \n",
       "3          230.388689          0.457263                      1297.342216   \n",
       "4          264.516013          0.498232                       731.845400   \n",
       "\n",
       "   Mud density [kg/m3]  Hole diameter [m]  Nonlinear1  Nonlinear2  Nonlinear3  \\\n",
       "0             2.949484           0.500000   -0.030589    0.822986    0.917557   \n",
       "1             3.338703           4.617729    0.090338    0.741262    0.831136   \n",
       "2             2.503559           6.177708   -0.915346    0.149370    0.537270   \n",
       "3             2.137124           6.089012   -0.885661    0.131785    0.941753   \n",
       "4             2.531889           5.303489    0.275052    0.447095    0.750145   \n",
       "\n",
       "   Temperature [C]  Bit depth [m]  Failure likelihood (%)  \n",
       "0        21.582837     902.435896               23.084672  \n",
       "1        27.133111     551.297785               16.010499  \n",
       "2        10.448471    1144.445348               18.217468  \n",
       "3        18.143884    1309.752689               20.377512  \n",
       "4        13.733294     739.591496               21.080085  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final dataframe\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
