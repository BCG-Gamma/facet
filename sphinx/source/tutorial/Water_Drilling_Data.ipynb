{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.082998Z",
     "start_time": "2020-09-08T20:43:40.170617Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.099017Z",
     "start_time": "2020-09-08T20:43:41.084640Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from typing import Union\n",
    "\n",
    "def data_sim(n=100,\n",
    "             intercept=-5,\n",
    "             linear_vars=10,\n",
    "             noise_vars=0,\n",
    "             corr_vars=0,\n",
    "             corr_type=\"AR1\",\n",
    "             corr_value=0,\n",
    "             mislabel=0,\n",
    "             surg_err=0.05,\n",
    "             bin_var_p=0,\n",
    "             bin_coef=0,\n",
    "             outcome=\"classification\",\n",
    "             regression_err=None,\n",
    "             drilling_ex=False\n",
    "             ):\n",
    "    \"\"\"\n",
    "    This function is for the most part a direct translation of the twoClassSim function from the R package caret.\n",
    "    Full credit for the approach used for simulating binary classification data foes to the Authors and contributors\n",
    "    of caret.\n",
    "\n",
    "    There are some modifications from the R implementation:\n",
    "    1. The ordinal outcome option has not been translated\n",
    "    2. The addition of another linear feature that is a copy of another used in the linear predictor with a small amount\n",
    "    of noise has been added to allow for the study of variable surrogacy\n",
    "    3. Option for a binary predictor and surrogate has also been added\n",
    "    4. Toggle option for regression versus classification has also been added\n",
    "\n",
    "    Source:\n",
    "        Caret: Kuhn, M. (2008). Caret package. Journal of Statistical Software, 28(5)\n",
    "        https://rdrr.io/cran/caret/man/twoClassSim.html\n",
    "\n",
    "    :param n: number of observations\n",
    "    :param intercept: value for the intercept which can be modified to generate class imbalance\n",
    "    :param linear_vars: number of linear features\n",
    "    :param noise_vars: number of noise features (i.e., do not contribute to the linear predictor)\n",
    "    :param corr_vars: number of correlated noise features\n",
    "    :param corr_type: type of correlation (exchangeable or auto-regressive) for correlated noise features\n",
    "    :param corr_value: correlation for correlated noise features\n",
    "    :param mislabel: proportion of mis-labelling of target if required\n",
    "    :param surg_err: degree of noise added to first linear predictor\n",
    "    :param bin_var_p: prevalence for a binary feature to include in linear predictor\n",
    "    :param bin_coef: coefficient for the impact of binary feature on linear predictor\n",
    "    :param outcome: can be either classification for a binary outcome or regression for a continuous outcome\n",
    "    :param regression_err: the error to be used in simulating a regression outcome\n",
    "    :param drilling_ex: flag to aplly specific modifications too the function\n",
    "    :return: data frame containing the simulated features and target for classification\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(seed=4763546)\n",
    "\n",
    "    # add two correlated normal features\n",
    "    sigma = np.array([[1, 0], [0, 1]]) #(0s on the diagonal, 1.3 to 0, make the features independant) covariance matrix\n",
    "    mu = [0, 0]\n",
    "    tmp_data = pd.DataFrame(np.random.multivariate_normal(mu, sigma, size=n), columns=[\"TwoFactor1\", \"TwoFactor2\"])\n",
    "\n",
    "    # add linear features\n",
    "    if linear_vars > 0:\n",
    "        lin_cols = ['Linear' + str(x) for x in range(1, linear_vars + 1)]\n",
    "        tmp_data = pd.concat([tmp_data, pd.DataFrame(np.random.normal(size=(n, linear_vars)), columns=lin_cols)],\n",
    "                             axis=1)\n",
    "\n",
    "    # add features for non-linear terms\n",
    "    tmp_data['Nonlinear1'] = pd.Series(np.random.uniform(low=-1.0, high=1.0, size=n))\n",
    "    tmp_data = pd.concat([tmp_data, pd.DataFrame(np.random.uniform(size=(n, 2)), columns=['Nonlinear2', 'Nonlinear3'])],\n",
    "                         axis=1)\n",
    "\n",
    "    # add noise variables as needed\n",
    "    if noise_vars > 0:\n",
    "        noise_cols = ['Noise' + str(x) for x in range(1, noise_vars + 1)]\n",
    "        tmp_data = pd.concat([tmp_data, pd.DataFrame(np.random.normal(size=(n, noise_vars)), columns=noise_cols)],\n",
    "                             axis=1)\n",
    "\n",
    "    # add correlated noise features\n",
    "    if corr_vars > 0:\n",
    "        if corr_type == \"exch\":\n",
    "            vc = corr_value * np.ones((corr_vars, corr_vars))\n",
    "            np.fill_diagonal(vc, 1)\n",
    "\n",
    "        elif corr_type == \"AR1\":\n",
    "            vc_values = corr_value ** np.arange(corr_vars)\n",
    "            vc = toeplitz(vc_values)\n",
    "\n",
    "        corr_cols = ['Corr' + str(x) for x in range(1, corr_vars + 1)]\n",
    "        tmp_data = pd.concat([tmp_data,\n",
    "                              pd.DataFrame(np.random.multivariate_normal(np.zeros(corr_vars), vc, size=n),\n",
    "                                           columns=corr_cols)],\n",
    "                             axis=1)\n",
    "\n",
    "    # add a surrogate linear feature\n",
    "    if linear_vars > 0:\n",
    "        tmp_data['Linear1_prime'] = tmp_data['Linear1'] + np.random.normal(0, surg_err, size=n)\n",
    "\n",
    "    # add a binary feature\n",
    "    if bin_var_p > 0:\n",
    "        tmp_data['Binary1'] = np.where(np.random.uniform(size=n) <= bin_var_p, 0, 1)\n",
    "\n",
    "    # generate contributions to linear predictor 4, 4, 2 - 0,0,4 or 5 means features will have no correlations but contributions of the predictions will only have interaction \n",
    "    lp = intercept + 0 * tmp_data.TwoFactor1 + 0 * tmp_data.TwoFactor2 + 5 * tmp_data.TwoFactor1 * tmp_data.TwoFactor2 \\\n",
    "         + tmp_data.Nonlinear1 ** 3 + 2 * np.exp(-6 * (tmp_data.Nonlinear1 - 0.3) ** 2) + \\\n",
    "         2 * np.sin(np.pi * tmp_data.Nonlinear2 * tmp_data.Nonlinear3)\n",
    "        \n",
    "\n",
    "    if linear_vars > 0:\n",
    "        lin_coeff = np.linspace(10, 1, num=linear_vars) / 4\n",
    "        # Set some negative coefficients of linear relationship with lp\n",
    "        neg_idx = [_ for _ in range(1, linear_vars, 2)]\n",
    "        lin_coeff[neg_idx] = lin_coeff[neg_idx] * -1\n",
    "        if drilling_ex:\n",
    "            lin_coeff[2] = 3.5\n",
    "            lp = lp + tmp_data[lin_cols[2]]*tmp_data.TwoFactor2*tmp_data.TwoFactor1*0.2\n",
    "        # Add linear relationship to lp\n",
    "        lp = lp + tmp_data[lin_cols].dot(lin_coeff)\n",
    "\n",
    "    if bin_var_p > 0:\n",
    "        lp = lp + bin_coef * tmp_data['Binary1']\n",
    "        tmp_data['Binary1_prime'] = 1 - tmp_data['Binary1']\n",
    "\n",
    "    if outcome == 'classification':\n",
    "\n",
    "        # convert to a probability\n",
    "        prob = 1 / (1 + np.exp(-lp))\n",
    "\n",
    "        # add mislabelling if desired - TO DO: need to fix\n",
    "        if (mislabel > 0) and (mislabel < 1):\n",
    "            shuffle_rows = np.random.choice(n, np.floor(n * mislabel), replace=False)\n",
    "            prob[shuffle_rows] = 1 - prob[shuffle_rows]\n",
    "\n",
    "        # generate target\n",
    "        tmp_data['target'] = np.where(prob <= np.random.uniform(size=n), 0, 1)\n",
    "\n",
    "    elif outcome == 'regression':\n",
    "\n",
    "        # continuous outcome based on linear predictor\n",
    "        tmp_data['target'] = np.random.normal(lp, regression_err, size=n)\n",
    "\n",
    "    return tmp_data\n",
    "\n",
    "\n",
    "def scale_var(df: pd.DataFrame, \n",
    "              feature_name: str, \n",
    "              min_: Union[int, float] =0, \n",
    "              max_: Union[int, float]=1) -> np.array: \n",
    "    \"\"\"\n",
    "    Takes in a data frame and applies a min-max scaler to given bounds for a single column\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(min_, max_))\n",
    "    scaled_arr = scaler.fit_transform(df[[feature_name]]).reshape(1, -1)[0]\n",
    "    return scaled_arr\n",
    "\n",
    "def refactor_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.rename({ \n",
    "        \"TwoFactor1\": \"Weight on bit (kg)\", # higher weight --> higher weight will increase risks of danger \n",
    "        \"TwoFactor2\": \"Rotation speed (rpm)\", # Rotation speed of the drilling bit (too fast rotation can lead to overheating, too low rotation renders drilling mnore difficult)         \n",
    "        \"Linear1\": \"Depth of operation (m)\", # lower point of the well\n",
    "        \"Linear1_prime\": \"Hole diameter (m)\", # Diameter of the hole (diameter diminishes as depth increases)\n",
    "        \"Nonlinear1\": \"Mud Flow in (m3/s)\", # Speed of mud circulation\n",
    "        \"Linear2\": \"Mud density (kg/L)\", # need to have equal mud and soil density to avoid well collapse (formation falling in well and blocking pipe) or mud loss (mud flowing in the formation)\n",
    "        \"Linear3\": \"Rate of Penetration (m/s)\", # higher RoP will provide less time for drilling engineers to observe real time data and adjust drilling parameter set up -> leading to a higher risk of incident (but more economic to drill faster)\n",
    "        \"Noise1\": \"Temperature (C)\", # Temperature at the drilling bit \n",
    "        \"target\": \"Failure likelihood (%)\"\n",
    "    }, axis=1, inplace=True)\n",
    "    \n",
    "    scaling_dict = { \n",
    "        'Weight on bit (kg)': [100, 500], \n",
    "        'Rotation speed (rpm)': [900, 15000],\n",
    "        'Rate of Penetration (m/s)': [0.001, 0.01],\n",
    "        #'Vertical depth of operation (m)': [0, 1500], \n",
    "        'Mud density (kg/L)': [0.5, 4],\n",
    "        'Hole diameter (m)': [0.5, 10], \n",
    "        'Temperature (C)': [0, 100], \n",
    "        'Depth of operation (m)': [0, 1500], \n",
    "        'Mud Flow in (m3/s)': [0, 100],\n",
    "        'Failure likelihood (%)': [0, 100]\n",
    "    }\n",
    "    df[\"Inverse Rate of Penetration (s/m)\"] = 1/df[\"Rate of Penetration (m/s)\"]\n",
    "\n",
    "    for k,v in scaling_dict.items(): \n",
    "        df.loc[:, k] = scale_var(df, k, v[0], v[1])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.113934Z",
     "start_time": "2020-09-08T20:43:41.101215Z"
    }
   },
   "outputs": [],
   "source": [
    "df = data_sim(n=500,\n",
    "             intercept=0,\n",
    "             linear_vars=4,\n",
    "             noise_vars=1,\n",
    "             corr_vars=0,\n",
    "             corr_type=\"AR1\",\n",
    "             corr_value=0.4,\n",
    "             mislabel=0,\n",
    "             surg_err=0.05,\n",
    "             bin_var_p=0,\n",
    "             bin_coef=0,\n",
    "             outcome=\"regression\",\n",
    "             regression_err=0.2,\n",
    "             drilling_ex=True\n",
    "             )\n",
    "df = refactor_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.168026Z",
     "start_time": "2020-09-08T20:43:41.150514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight on bit (kg)</th>\n",
       "      <th>Rotation speed (rpm)</th>\n",
       "      <th>Depth of operation (m)</th>\n",
       "      <th>Mud density (kg/L)</th>\n",
       "      <th>Rate of Penetration (m/s)</th>\n",
       "      <th>Linear4</th>\n",
       "      <th>Mud Flow in (m3/s)</th>\n",
       "      <th>Nonlinear2</th>\n",
       "      <th>Nonlinear3</th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>Hole diameter (m)</th>\n",
       "      <th>Failure likelihood (%)</th>\n",
       "      <th>Inverse Rate of Penetration (s/m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>306.141821</td>\n",
       "      <td>9849.952938</td>\n",
       "      <td>927.968837</td>\n",
       "      <td>2.902467</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-0.385633</td>\n",
       "      <td>50.299606</td>\n",
       "      <td>0.793721</td>\n",
       "      <td>0.153503</td>\n",
       "      <td>34.516570</td>\n",
       "      <td>6.373932</td>\n",
       "      <td>25.092477</td>\n",
       "      <td>-0.339774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324.039405</td>\n",
       "      <td>10744.516916</td>\n",
       "      <td>1106.187754</td>\n",
       "      <td>2.106770</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.199908</td>\n",
       "      <td>72.140061</td>\n",
       "      <td>0.155269</td>\n",
       "      <td>0.767234</td>\n",
       "      <td>41.861162</td>\n",
       "      <td>7.507640</td>\n",
       "      <td>56.071090</td>\n",
       "      <td>0.583143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>345.377055</td>\n",
       "      <td>5393.241061</td>\n",
       "      <td>898.168085</td>\n",
       "      <td>3.909455</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.647058</td>\n",
       "      <td>10.908230</td>\n",
       "      <td>0.598722</td>\n",
       "      <td>0.101157</td>\n",
       "      <td>58.560955</td>\n",
       "      <td>6.180673</td>\n",
       "      <td>29.844640</td>\n",
       "      <td>-2.817546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356.709497</td>\n",
       "      <td>6776.865696</td>\n",
       "      <td>769.165223</td>\n",
       "      <td>2.473607</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>-0.419456</td>\n",
       "      <td>51.029350</td>\n",
       "      <td>0.588158</td>\n",
       "      <td>0.464393</td>\n",
       "      <td>72.925042</td>\n",
       "      <td>5.368265</td>\n",
       "      <td>41.938061</td>\n",
       "      <td>7.019297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328.437275</td>\n",
       "      <td>6024.116387</td>\n",
       "      <td>215.202605</td>\n",
       "      <td>3.033681</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>44.159394</td>\n",
       "      <td>0.278210</td>\n",
       "      <td>0.190692</td>\n",
       "      <td>43.992966</td>\n",
       "      <td>2.092908</td>\n",
       "      <td>24.455330</td>\n",
       "      <td>-0.886233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight on bit (kg)  Rotation speed (rpm)  Depth of operation (m)  \\\n",
       "0          306.141821           9849.952938              927.968837   \n",
       "1          324.039405          10744.516916             1106.187754   \n",
       "2          345.377055           5393.241061              898.168085   \n",
       "3          356.709497           6776.865696              769.165223   \n",
       "4          328.437275           6024.116387              215.202605   \n",
       "\n",
       "   Mud density (kg/L)  Rate of Penetration (m/s)   Linear4  \\\n",
       "0            2.902467                   0.001000 -0.385633   \n",
       "1            2.106770                   0.007870  0.199908   \n",
       "2            3.909455                   0.004817  0.647058   \n",
       "3            2.473607                   0.005551 -0.419456   \n",
       "4            3.033681                   0.003676  0.006490   \n",
       "\n",
       "   Mud Flow in (m3/s)  Nonlinear2  Nonlinear3  Temperature (C)  \\\n",
       "0           50.299606    0.793721    0.153503        34.516570   \n",
       "1           72.140061    0.155269    0.767234        41.861162   \n",
       "2           10.908230    0.598722    0.101157        58.560955   \n",
       "3           51.029350    0.588158    0.464393        72.925042   \n",
       "4           44.159394    0.278210    0.190692        43.992966   \n",
       "\n",
       "   Hole diameter (m)  Failure likelihood (%)  \\\n",
       "0           6.373932               25.092477   \n",
       "1           7.507640               56.071090   \n",
       "2           6.180673               29.844640   \n",
       "3           5.368265               41.938061   \n",
       "4           2.092908               24.455330   \n",
       "\n",
       "   Inverse Rate of Penetration (s/m)  \n",
       "0                          -0.339774  \n",
       "1                           0.583143  \n",
       "2                          -2.817546  \n",
       "3                           7.019297  \n",
       "4                          -0.886233  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"water_drill_dataset.csv\", sep=\";\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facet-develop",
   "language": "python",
   "name": "facet-develop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
