{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.082998Z",
     "start_time": "2020-09-08T20:43:40.170617Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.099017Z",
     "start_time": "2020-09-08T20:43:41.084640Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_sim(n=100,\n",
    "             intercept=-5,\n",
    "             linear_vars=10,\n",
    "             noise_vars=0,\n",
    "             corr_vars=0,\n",
    "             corr_type=\"AR1\",\n",
    "             corr_value=0,\n",
    "             mislabel=0,\n",
    "             surg_err=0.05,\n",
    "             bin_var_p=0,\n",
    "             bin_coef=0,\n",
    "             outcome=\"classification\",\n",
    "             regression_err=None,\n",
    "             ):\n",
    "    \"\"\"\n",
    "    This function is for the most part a direct translation of the twoClassSim function from the R package caret.\n",
    "    Full credit for the approach used for simulating binary classification data foes to the Authors and contributors\n",
    "    of caret.\n",
    "\n",
    "    There are some modifications from the R implementation:\n",
    "    1. The ordinal outcome option has not been translated\n",
    "    2. The addition of another linear feature that is a copy of another used in the linear predictor with a small amount\n",
    "    of noise has been added to allow for the study of variable surrogacy\n",
    "    3. Option for a binary predictor and surrogate has also been added\n",
    "    4. Toggle option for regression versus classification has also been added\n",
    "\n",
    "    Source:\n",
    "        Caret: Kuhn, M. (2008). Caret package. Journal of Statistical Software, 28(5)\n",
    "        https://rdrr.io/cran/caret/man/twoClassSim.html\n",
    "\n",
    "    :param n: number of observations\n",
    "    :param intercept: value for the intercept which can be modified to generate class imbalance\n",
    "    :param linear_vars: number of linear features\n",
    "    :param noise_vars: number of noise features (i.e., do not contribute to the linear predictor)\n",
    "    :param corr_vars: number of correlated noise features\n",
    "    :param corr_type: type of correlation (exchangeable or auto-regressive) for correlated noise features\n",
    "    :param corr_value: correlation for correlated noise features\n",
    "    :param mislabel: proportion of mis-labelling of target if required\n",
    "    :param surg_err: degree of noise added to first linear predictor\n",
    "    :param bin_var_p: prevalence for a binary feature to include in linear predictor\n",
    "    :param bin_coef: coefficient for the impact of binary feature on linear predictor\n",
    "    :param outcome: can be either classification for a binary outcome or regression for a continuous outcome\n",
    "    :param regression_err: the error to be used in simulating a regression outcome\n",
    "    :return: data frame containing the simulated features and target for classification\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(seed=4763546)\n",
    "\n",
    "    # add two correlated normal features\n",
    "    sigma = np.array([[2, 1.3], [1.3, 2]])\n",
    "    mu = [0, 0]\n",
    "    tmp_data = pd.DataFrame(np.random.multivariate_normal(mu, sigma, size=n), columns=[\"TwoFactor1\", \"TwoFactor2\"])\n",
    "\n",
    "    # add linear features\n",
    "    if linear_vars > 0:\n",
    "        lin_cols = ['Linear' + str(x) for x in range(1, linear_vars + 1)]\n",
    "        tmp_data = pd.concat([tmp_data, pd.DataFrame(np.random.normal(size=(n, linear_vars)), columns=lin_cols)],\n",
    "                             axis=1)\n",
    "\n",
    "    # add features for non-linear terms\n",
    "    tmp_data['Nonlinear1'] = pd.Series(np.random.uniform(low=-1.0, high=1.0, size=n))\n",
    "    tmp_data = pd.concat([tmp_data, pd.DataFrame(np.random.uniform(size=(n, 2)), columns=['Nonlinear2', 'Nonlinear3'])],\n",
    "                         axis=1)\n",
    "\n",
    "    # add noise variables as needed\n",
    "    if noise_vars > 0:\n",
    "        noise_cols = ['Noise' + str(x) for x in range(1, noise_vars + 1)]\n",
    "        tmp_data = pd.concat([tmp_data, pd.DataFrame(np.random.normal(size=(n, noise_vars)), columns=noise_cols)],\n",
    "                             axis=1)\n",
    "\n",
    "    # add correlated noise features\n",
    "    if corr_vars > 0:\n",
    "        if corr_type == \"exch\":\n",
    "            vc = corr_value * np.ones((corr_vars, corr_vars))\n",
    "            np.fill_diagonal(vc, 1)\n",
    "\n",
    "        elif corr_type == \"AR1\":\n",
    "            vc_values = corr_value ** np.arange(corr_vars)\n",
    "            vc = toeplitz(vc_values)\n",
    "\n",
    "        corr_cols = ['Corr' + str(x) for x in range(1, corr_vars + 1)]\n",
    "        tmp_data = pd.concat([tmp_data,\n",
    "                              pd.DataFrame(np.random.multivariate_normal(np.zeros(corr_vars), vc, size=n),\n",
    "                                           columns=corr_cols)],\n",
    "                             axis=1)\n",
    "\n",
    "    # add a surrogate linear feature\n",
    "    if linear_vars > 0:\n",
    "        tmp_data['Linear1_prime'] = tmp_data['Linear1'] + np.random.normal(0, surg_err, size=n)\n",
    "\n",
    "    # add a binary feature\n",
    "    if bin_var_p > 0:\n",
    "        tmp_data['Binary1'] = np.where(np.random.uniform(size=n) <= bin_var_p, 0, 1)\n",
    "\n",
    "    # generate contributions to linear predictor 4, 4, 2\n",
    "    lp = intercept + 4 * tmp_data.TwoFactor1 + 4 * tmp_data.TwoFactor2 + 2 * tmp_data.TwoFactor1 * tmp_data.TwoFactor2 \\\n",
    "         + tmp_data.Nonlinear1 ** 3 + 2 * np.exp(-6 * (tmp_data.Nonlinear1 - 0.3) ** 2) + \\\n",
    "         2 * np.sin(np.pi * tmp_data.Nonlinear2 * tmp_data.Nonlinear3)\n",
    "        \n",
    "\n",
    "    if linear_vars > 0:\n",
    "        lin_coeff = np.linspace(10, 1, num=linear_vars) / 4\n",
    "        neg_idx = [_ for _ in range(1, linear_vars, 2)]\n",
    "        lin_coeff[neg_idx] = lin_coeff[neg_idx] * -1\n",
    "        lp = lp + tmp_data[lin_cols].dot(lin_coeff)\n",
    "\n",
    "    if bin_var_p > 0:\n",
    "        lp = lp + bin_coef * tmp_data['Binary1']\n",
    "        tmp_data['Binary1_prime'] = 1 - tmp_data['Binary1']\n",
    "\n",
    "    if outcome == 'classification':\n",
    "\n",
    "        # convert to a probability\n",
    "        prob = 1 / (1 + np.exp(-lp))\n",
    "\n",
    "        # add mislabelling if desired - TO DO: need to fix\n",
    "        if (mislabel > 0) and (mislabel < 1):\n",
    "            shuffle_rows = np.random.choice(n, np.floor(n * mislabel), replace=False)\n",
    "            prob[shuffle_rows] = 1 - prob[shuffle_rows]\n",
    "\n",
    "        # generate target\n",
    "        tmp_data['target'] = np.where(prob <= np.random.uniform(size=n), 0, 1)\n",
    "\n",
    "    elif outcome == 'regression':\n",
    "\n",
    "        # continuous outcome based on linear predictor\n",
    "        tmp_data['target'] = np.random.normal(lp, regression_err, size=n)\n",
    "\n",
    "    return tmp_data\n",
    "\n",
    "\n",
    "def scale_var(df: pd.DataFrame, \n",
    "              feature_name: str, \n",
    "              min_: Union[int, float] =0, \n",
    "              max_: Union[int, float]=1) -> np.array: \n",
    "    \"\"\"\n",
    "    Takes in a data frame and applies a min-max scaler to given bounds for a single column\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(min_, max_))\n",
    "    scaled_arr = scaler.fit_transform(df[[feature_name]]).reshape(1, -1)[0]\n",
    "    return scaled_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.113934Z",
     "start_time": "2020-09-08T20:43:41.101215Z"
    }
   },
   "outputs": [],
   "source": [
    "df = data_sim(n=500,\n",
    "             intercept=0,\n",
    "             linear_vars=3,\n",
    "             noise_vars=1,\n",
    "             corr_vars=0,\n",
    "             corr_type=\"AR1\",\n",
    "             corr_value=0.4,\n",
    "             mislabel=0,\n",
    "             surg_err=0.05,\n",
    "             bin_var_p=0,\n",
    "             bin_coef=0,\n",
    "             outcome=\"regression\",\n",
    "             regression_err=0.2,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.119348Z",
     "start_time": "2020-09-08T20:43:41.115607Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename({ \n",
    "    \"TwoFactor1\": \"Weight on bit [kg]\", # higher weight --> higher weight will increase risks of danger \n",
    "    \"TwoFactor2\": \"Drill rate [m/s]\", # higher drill rate --> higher drill rate will provide less time for drilling engineers to observe real time data and adjust drilling parameter set up -> leading to a higher risk of incident (but more economic to drill faster)\n",
    "    \"Linear1\": \"Vertical depth of operation [m]\", # lower point of the well\n",
    "    \"Linear1_prime\": \"Bit depth [m]\", # current position of the drilling bit\n",
    "    \"Linear2\": \"Mud density [kg/m3]\", # need to have equal mud and soil density to avoid well collapse (formation falling in well and blocking pipe) or mud loss (mud flowing in the formation)\n",
    "    \"Linear3\": \"Hole diameter [m]\", # Diameter of the hole (diameter diminishes as depth increases)\n",
    "    \"Noise1\": \"Temperature [C]\", # Temperature at the drilling bit \n",
    "    \"target\": \"Failure likelihood (%)\"\n",
    "}, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.148979Z",
     "start_time": "2020-09-08T20:43:41.121208Z"
    }
   },
   "outputs": [],
   "source": [
    "scaling_dict = { \n",
    "    'Weight on bit [kg]': [100, 500], \n",
    "    'Drill rate [m/s]': [0.1, 1],   \n",
    "    'Vertical depth of operation [m]': [0, 1500], \n",
    "    'Mud density [kg/m3]': [0.5, 4],\n",
    "    'Hole diameter [m]': [0.5, 10], \n",
    "    'Temperature [C]': [0, 40], \n",
    "    'Bit depth [m]': [0, 1500], \n",
    "    'Failure likelihood (%)': [0, 100]\n",
    "}\n",
    "\n",
    "for k,v in scaling_dict.items(): \n",
    "    df.loc[:, k] = scale_var(df, k, v[0], v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T20:43:41.168026Z",
     "start_time": "2020-09-08T20:43:41.150514Z"
    }
   },
   "outputs": [],
   "source": [
    "# final dataframe\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
