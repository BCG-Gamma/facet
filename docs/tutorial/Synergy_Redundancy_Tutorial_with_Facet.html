
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Intuition on synergy &amp; redundancy &#8212; facet  documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/gamma.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/js/gamma.js"></script>
    <script src="../_static/js/versions.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Development Guidelines" href="../contribution_guide.html" />
    <link rel="prev" title="Standard Scikit-learn Classification Summary with FACET" href="Scikit-learn_classifier_summaries_using_FACET.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <img src="../_static/Gamma_Facet_Logo_RGB_LB.svg" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../getting_started/getting_started.html">Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../apidoc/facet.html">API reference</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="../tutorials.html">Tutorials</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../contribution_guide.html">Development Guidelines</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../faqs.html">FAQ</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../about_us.html">About us</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="Water_Drilling_Incident_Classification_with_Facet.html">Introduction to FACET</a>
                </li>
            
          
            
                <li class="">
                    <a href="Predictive_Maintenance_Regression_with_Facet.html">Regression with FACET: Predictive Maintenance</a>
                </li>
            
          
            
                <li class="">
                    <a href="Classification_with_Facet.html">Classification with FACET: Prediabetes Study</a>
                </li>
            
          
            
                <li class="">
                    <a href="Model_simulation_deep_dive.html">Bootstrap simulation with FACET</a>
                </li>
            
          
            
                <li class="">
                    <a href="Scikit-learn_classifier_summaries_using_FACET.html">Standard Scikit-learn Classification Summary with FACET</a>
                </li>
            
          
            
                <li class="active">
                    <a href="">Intuition on synergy & redundancy</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#" class="nav-link">Intuition on synergy & redundancy</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Required-imports" class="nav-link">Required imports</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Simulating-data" class="nav-link">Simulating data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#SHAP,-Redundancy-and-Synergy" class="nav-link">SHAP, Redundancy and Synergy</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Understanding-how-redundancy-and-synergy-change-with-feature-correlation-and-interaction" class="nav-link">Understanding how redundancy and synergy change with feature correlation and interaction</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#Synergy" class="nav-link">Synergy</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#Redundancy" class="nav-link">Redundancy</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#How-overfitting-affects-the-accuracy-of-redundancy-and-synergy-estimates" class="nav-link">How overfitting affects the accuracy of redundancy and synergy estimates</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Summary" class="nav-link">Summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#What-can-you-do-next?" class="nav-link">What can you do next?</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Appendix" class="nav-link">Appendix</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#Data-simulation-code" class="nav-link">Data simulation code</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#Simulation-study-1-code" class="nav-link">Simulation study 1 code</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#Simulation-study-2-code" class="nav-link">Simulation study 2 code</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<p><img alt="157f2146e58c4dc78681c62eb4ec0791" class="no-scaled-link" src="../_images/Gamma_Facet_Logo_RGB_LB2.svg" width="500" /></p>
<div class="section" id="Intuition-on-synergy-&amp;-redundancy">
<h1>Intuition on synergy &amp; redundancy<a class="headerlink" href="#Intuition-on-synergy-&-redundancy" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<p>FACET is composed of the following key components:</p>
<ul>
<li><p><strong>Model Inspection</strong></p>
<p>FACET introduces a new algorithm to quantify dependencies and interactions between features in ML models. This new tool for human-explainable AI adds a new, global perspective to the observation-level explanations provided by the popular <a class="reference external" href="https://shap.readthedocs.io/en/latest/">SHAP</a> approach. To learn more about FACET’s model inspection capabilities, see the getting started example below.</p>
</li>
<li><p><strong>Model Simulation</strong></p>
<p>FACET’s model simulation algorithms use ML models for <em>virtual experiments</em> to help identify scenarios that optimise predicted outcomes. To quantify the uncertainty in simulations, FACET utilises a range of bootstrapping algorithms including stationary and stratified bootstraps. For an example of FACET’s bootstrap simulations, see the getting started example below.</p>
</li>
<li><p><strong>Enhanced Machine Learning Workflow</strong></p>
<p>FACET offers an efficient and transparent machine learning workflow, enhancing <a class="reference external" href="https://scikit-learn.org/stable/index.html">scikit-learn</a>’s tried and tested pipelining paradigm with new capabilities for model selection, inspection, and simulation. FACET also introduces <a class="reference external" href="https://github.com/BCG-Gamma/sklearndf">sklearndf</a>, an augmented version of <em>scikit-learn</em> with enhanced support for <em>pandas</em> dataframes that ensures end-to-end traceability of features.</p>
</li>
</ul>
<hr class="docutils" />
<p><strong>Context</strong></p>
<p>With the advanced capabilities FACET provides by extending SHAP-based model inspection, it is important to <strong>gain some intuition for how the newly introduced measures for feature redundancy and synergy can vary</strong>. As SHAP values represent post-processing after data preparation, feature engineering, preprocessing and model selection/tuning, minimal simulation studies offer a way to make the connection as direct as possible.</p>
<p>In this FACET tutorial we will conduct two simulation studies to gain intuition about synergy and redundancy:</p>
<ol class="arabic simple">
<li><p>Explore patterns in synergy and redundancy as a function of the individual and joint contribution of two continuous features in predicting a binary target where the features have varying degrees of correlation.</p></li>
<li><p>Explore how overfitting affects the accuracy of redundancy and synergy estimates for a random forest classifier by varying the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> parameter.</p></li>
</ol>
<hr class="docutils" />
<p><strong>Tutorial outline</strong></p>
<ol class="arabic simple">
<li><p><a class="reference external" href="#Required-imports">Required imports</a></p></li>
<li><p><a class="reference external" href="#Simulating-data">Simulating data</a></p></li>
<li><p><a class="reference external" href="#SHAP,-Redundancy-and-Synergy">SHAP, Redundancy and Synergy</a></p></li>
<li><p><a class="reference external" href="#Understanding-how-redundancy-and-synergy-change-with-feature-correlation-and-interaction">Understanding how redundancy and synergy change with feature correlation and interaction</a></p></li>
<li><p><a class="reference external" href="#How-overfitting-affects-the-accuracy-of-redundancy-and-synergy-estimates">How overfitting affects the accuracy of redundancy and synergy estimates</a></p></li>
<li><p><a class="reference external" href="#Summary">Summary</a></p></li>
<li><p><a class="reference external" href="#What-can-you-do-next?">What can you do next?</a></p></li>
<li><p><a class="reference external" href="#Appendix">Appendix</a></p></li>
</ol>
</div>
<div class="section" id="Required-imports">
<h1>Required imports<a class="headerlink" href="#Required-imports" title="Permalink to this headline">¶</a></h1>
<p>In order to run this notebook, we will import not only the FACET package, but also other packages useful to solve this task. Overall, we can break down the imports into three categories:</p>
<ol class="arabic simple">
<li><p>Common packages (pandas, matplotlib, etc.)</p></li>
<li><p>Required FACET classes (inspection, selection, validation, simulation, etc.)</p></li>
<li><p>sklearndf a BCG GAMMA package that simplifies pipelining (see on <a class="reference external" href="https://github.com/BCG-Gamma/sklearndf/">GitHub</a>).</p></li>
</ol>
<p><strong>Common package imports</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">toeplitz</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">shap</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;darkgrid&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RepeatedKFold</span>
</pre></div>
</div>
</div>
<p><strong>FACET imports</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">facet.data</span> <span class="kn">import</span> <span class="n">Sample</span>
<span class="kn">from</span> <span class="nn">facet.crossfit</span> <span class="kn">import</span> <span class="n">LearnerCrossfit</span>
<span class="kn">from</span> <span class="nn">facet.inspection</span> <span class="kn">import</span> <span class="n">LearnerInspector</span>
<span class="kn">from</span> <span class="nn">facet.selection</span> <span class="kn">import</span> <span class="n">LearnerRanker</span><span class="p">,</span> <span class="n">LearnerGrid</span>
<span class="kn">from</span> <span class="nn">facet.validation</span> <span class="kn">import</span> <span class="n">BootstrapCV</span>
</pre></div>
</div>
</div>
<p><strong>sklearndf imports</strong></p>
<p>Instead of using the “regular” scikit-learn package, we are going to use sklearndf (see on <a class="reference external" href="https://github.com/BCG-Gamma/sklearndf/">GitHub</a>). sklearndf is an open source library designed to address a common issue with scikit-learn: the outputs of transformers are numpy arrays, even when the input is a data frame. However, to inspect a model it is essential to keep track of the feature names. sklearndf retains all the functionality available through scikit-learn plus the feature traceability
and usability associated with Pandas data frames. Additionally, the names of all your favourite scikit-learn functions are the same except for DF on the end. For example, the standard scikit-learn import:</p>
<p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">sklearn.pipeline</span> <span class="pre">import</span> <span class="pre">Pipeline</span></code></p>
<p>becomes:</p>
<p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">sklearndf.pipeline</span> <span class="pre">import</span> <span class="pre">PipelineDF</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearndf.pipeline</span> <span class="kn">import</span> <span class="n">PipelineDF</span><span class="p">,</span> <span class="n">ClassifierPipelineDF</span><span class="p">,</span> <span class="n">RegressorPipelineDF</span>
<span class="kn">from</span> <span class="nn">sklearndf.classification</span> <span class="kn">import</span> <span class="n">RandomForestClassifierDF</span>
<span class="kn">from</span> <span class="nn">sklearndf.regression</span> <span class="kn">import</span> <span class="n">RandomForestRegressorDF</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Simulating-data">
<h1>Simulating data<a class="headerlink" href="#Simulating-data" title="Permalink to this headline">¶</a></h1>
<p>When analysing data, features are often <a class="reference external" href="https://en.wikipedia.org/wiki/Correlation_and_dependence">correlated</a> (degree to which two features are related) or <a class="reference external" href="https://en.wikipedia.org/wiki/Interaction_(statistics)">interact</a> with each other (the combined features improve prediction performance). As part of a robust data science process, identifying and understanding the impact these data characteristics have on a predictive model, and hence conclusions, is important.</p>
<p>To demonstrate how the capabilities of FACET’s novel algorithm can help with this task, this tutorial uses simulation to control the characteristics of our data and then see how these are reflected in our inspection using FACET.</p>
<p>We use the following data generating process to simulate data for this tutorial:</p>
<ul class="simple">
<li><p>Step 1. Generate a pair of features <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span>, from a standard normal distribution with linear correlation (<span class="math notranslate nohighlight">\(\rho\)</span>). Importantly rho controls the extent of linear correlation between the two features.</p></li>
<li><p>Step 2: Generate the linear predictor <span class="math notranslate nohighlight">\(lp\)</span> using pre-defined coefficients <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>, <span class="math notranslate nohighlight">\(\beta_2\)</span>, <span class="math notranslate nohighlight">\(\beta_3\)</span>. Importantly <span class="math notranslate nohighlight">\(\beta_3\)</span> controls the contribution of the interaction between the two features (<span class="math notranslate nohighlight">\(X_1 \times X_2\)</span>).</p></li>
</ul>
<p>In the case of regression:</p>
<ul class="simple">
<li><p>Step 3: Generate the target variable (y) using the linear predictor plus error, where the error follows a standard normal distribution.</p></li>
</ul>
<p>Or in the case of classification:</p>
<ul class="simple">
<li><p>Step 3: Generate the probability of the outcome using the <a class="reference external" href="https://www.rdocumentation.org/packages/rgr/versions/1.1.15/topics/expit">expit</a> transformation of the linear predictor.</p></li>
<li><p>Step 4: Convert the probability of the outcome to a 0/1 target variable (y) by simulating from a uniform random variable and comparing with the probability. Where U is less than p we set a value of 1 for the target and 0 otherwise.</p></li>
</ul>
<p>This process provides a dataset with two features and a target binary variable which we can predict using a classifier. Further, the simulated dataset will have a determined amount of correlation and interaction between the two features <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span>.</p>
<p>The function used to simulate data according to the above specifications is <code class="docutils literal notranslate"><span class="pre">sim_interaction()</span></code> and can be found in the <a class="reference external" href="#Data-simulation-code">Appendix</a>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}(X_1, X_2) \sim N\left[\left(\begin{array}{c} 0\\0 \end{array}\right), \left(\begin{array}{cc} 1 &amp; \rho\\ \rho &amp; 1 \end{array}\right)\right]\end{split}\]</div>
<div class="math notranslate nohighlight">
\[lp =  \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2\]</div>
<p>For regression:</p>
<div class="math notranslate nohighlight">
\[e \sim \textrm{N}(0,1)\]</div>
<div class="math notranslate nohighlight">
\[y = lp + e\]</div>
<p>For classification:</p>
<div class="math notranslate nohighlight">
\[p = \cfrac{1}{1 + exp(-lp)}\]</div>
<div class="math notranslate nohighlight">
\[U \sim \textrm{U}(0,1)\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}y = \begin{cases}
1 &amp; U &lt; p  \\
0 &amp; U \geq p
\end{cases}\end{split}\]</div>
<p>Importantly we use the <a class="reference external" href="https://en.wikipedia.org/wiki/Correlation_and_dependence">correlation</a> <span class="math notranslate nohighlight">\(\rho\)</span> (degree to which two features are linearly related) between features to induce redundancy, and the balance between an interaction (<span class="math notranslate nohighlight">\(\beta_3\)</span>) and main effects (<span class="math notranslate nohighlight">\(\beta_1, \beta_2\)</span>) to induce synergy. For example, as the correlation gets higher, we expect higher redundancy, and as the interaction gets stronger and the main effects get weaker, we expect higher synergy.</p>
<p>The function used to simulate data according to the above specifications is <code class="docutils literal notranslate"><span class="pre">sim_interaction()</span></code> and can be found in the <a class="reference external" href="#Data-simulation-code">Appendix</a>.</p>
</div>
<div class="section" id="SHAP,-Redundancy-and-Synergy">
<h1>SHAP, Redundancy and Synergy<a class="headerlink" href="#SHAP,-Redundancy-and-Synergy" title="Permalink to this headline">¶</a></h1>
<p>The <a class="reference external" href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions">SHAP approach</a> has become the standard method for model inspection. SHAP values are used to explain the additive contribution of each feature to the prediction for each observation (i.e., explain <strong>individual</strong> predictions).</p>
<p>The FACET <code class="docutils literal notranslate"><span class="pre">LearnerInspector</span></code> computes SHAP values for each crossfit (i.e., a CV fold or bootstrap resample) using the best model identified by the <code class="docutils literal notranslate"><span class="pre">LearnerRanker</span></code>. The FACET <code class="docutils literal notranslate"><span class="pre">LearnerInspector</span></code> then provides advanced model inspection through new SHAP-based summary metrics for understanding pairwise feature redundancy and synergy. Redundancy and synergy are calculated using a new algorithm to understand model predictions from a <strong>global perspective</strong> to complement local SHAP.</p>
<p>The definitions of synergy and redundancy are as follows:</p>
<ul>
<li><p><strong>Synergy</strong></p>
<p>The degree to which the model combines information from one feature with another to predict the target. For example, let’s assume we are predicting cardiovascular health using age and gender and the fitted model includes a complex interaction between them. This means these two features are synergistic for predicting cardiovascular health. Further, both features are important to the model and removing either one would significantly impact performance. Let’s assume age brings more information
to the joint contribution than gender. This asymmetric contribution means the synergy for (age, gender) is less than the synergy for (gender, age). To think about it another way, imagine the prediction is a coordinate you are trying to reach. From your starting point, age gets you much closer to this point than gender, however, you need both to get there. Synergy reflects the fact that gender gets more help from age (higher synergy from the perspective of gender) than age does from gender
(lower synergy from the perspective of age) to reach the prediction. <em>This leads to an important point: synergy is a naturally asymmetric property of the global information two interacting features contribute to the model predictions.</em> Synergy is expressed as a percentage ranging from 0% (full autonomy) to 100% (full synergy).</p>
</li>
<li><p><strong>Redundancy</strong></p>
<p>The degree to which a feature in a model duplicates the information of a second feature to predict the target. For example, let’s assume we had house size and number of bedrooms for predicting house price. These features capture similar information as the more bedrooms the larger the house and likely a higher price on average. The redundancy for (number of bedrooms, house size) will be greater than the redundancy for (house size, number of bedrooms). This is because house size “knows” more of
what number of bedrooms does for predicting house price than vice-versa. Hence, there is greater redundancy from the perspective of number of bedrooms. Another way to think about it is removing house size will be more detrimental to model performance than removing number of bedrooms, as house size can better compensate for the absence of number of bedrooms. This also implies that house size would be a more important feature than number of bedrooms in the model. <em>The important point here is
that like synergy, redundancy is a naturally asymmetric property of the global information feature pairs have for predicting an outcome.</em> Redundancy is expressed as a percentage ranging from 0% (full uniqueness) to 100% (full redundancy).</p>
</li>
</ul>
<p>In brief, redundancy represents the shared information between two features and synergy represents the degree to which one feature combines with another to generate a prediction. It is also important to recognize:</p>
<ul class="simple">
<li><p>that any pair of features may have both redundancy and synergy.</p></li>
<li><p>that <strong>SHAP values are dependent upon the model, they represent what the model catches about reality, not the reality</strong>. For example, under or over fitting will influence redundancy and synergy.</p></li>
<li><p>If two features A and B both contribute to predictions of a model, then correlation translates to redundancy and interaction translates to synergy.</p></li>
</ul>
</div>
<div class="section" id="Understanding-how-redundancy-and-synergy-change-with-feature-correlation-and-interaction">
<h1>Understanding how redundancy and synergy change with feature correlation and interaction<a class="headerlink" href="#Understanding-how-redundancy-and-synergy-change-with-feature-correlation-and-interaction" title="Permalink to this headline">¶</a></h1>
<p>Now that we have a methodology to build a dataset with more or less correlation, main feature effects and combined (interaction) effects, we will evaluate how FACET’s synergy and redundancy values will change depending on the dataset. To explore how redundancy only changes we use the following parameters for data generation:</p>
<ul class="simple">
<li><p>intercept (<span class="math notranslate nohighlight">\(\beta_0\)</span>) = <code class="docutils literal notranslate"><span class="pre">[0]</span></code></p></li>
<li><p>main effects (<span class="math notranslate nohighlight">\(\beta_1, \beta_2\)</span>) = <code class="docutils literal notranslate"><span class="pre">[(0.5,</span> <span class="pre">4),</span> <span class="pre">(1,</span> <span class="pre">3),</span> <span class="pre">(2,</span> <span class="pre">2),</span> <span class="pre">(3,</span> <span class="pre">1),</span> <span class="pre">(4,</span> <span class="pre">0.5)]</span></code></p></li>
<li><p>interaction (<span class="math notranslate nohighlight">\(\beta_3\)</span>) = <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">4]</span></code></p></li>
<li><p>correlation (<span class="math notranslate nohighlight">\(\rho\)</span>) = <code class="docutils literal notranslate"><span class="pre">[0.2,</span> <span class="pre">0.5,</span> <span class="pre">0.8]</span></code></p></li>
</ul>
<p>For each combination of parameters above we simulate 20 datasets with 1000 observations. Model fitting is performed using 10 repeated 5-fold CV. The learner is a Random Forest regressor with default hyperparameters.</p>
<p>The code used to generate the data presented is shown in the <a class="reference external" href="#Simulation-study-1A-code">Appendix</a>. You can experiment with the code and perform your own simulation studies, just be aware that it may take a little time to run.</p>
<div class="section" id="Synergy">
<h2>Synergy<a class="headerlink" href="#Synergy" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">long_sim1_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;sphinx/source/tutorial/regression_sim1.csv&quot;</span><span class="p">)</span>

<span class="c1"># create summary plot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">([</span><span class="s2">&quot;#30c1d7&quot;</span><span class="p">,</span> <span class="s2">&quot;#295e7e&quot;</span><span class="p">,</span> <span class="s2">&quot;#787878&quot;</span><span class="p">])</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">FacetGrid</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">long_sim1_data</span><span class="p">[</span><span class="n">long_sim1_data</span><span class="p">[</span><span class="s1">&#39;FACET Metric&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Synergy&#39;</span><span class="p">],</span>
    <span class="n">col</span><span class="o">=</span><span class="s2">&quot;Interaction&quot;</span><span class="p">,</span>
    <span class="n">row</span><span class="o">=</span><span class="s1">&#39;Correlation&#39;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Metric Type&quot;</span><span class="p">,</span>
    <span class="n">margin_titles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">,</span>
    <span class="s2">&quot;x_val&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Metric Value&quot;</span><span class="p">,</span>
    <span class="n">estimator</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
    <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">g</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;(0.5, 4)&#39;</span><span class="p">,</span> <span class="s1">&#39;(1, 3)&#39;</span><span class="p">,</span> <span class="s1">&#39;(2, 2)&#39;</span><span class="p">,</span> <span class="s1">&#39;(3, 1)&#39;</span><span class="p">,</span> <span class="s1">&#39;(4, 0.5)&#39;</span><span class="p">])</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
<span class="n">g</span><span class="o">.</span><span class="n">set_axis_labels</span><span class="p">(</span><span class="s2">&quot;Main Effect Coefficients (A, B)&quot;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_Synergy_Redundancy_Tutorial_with_Facet_19_0.png" src="../_images/tutorial_Synergy_Redundancy_Tutorial_with_Facet_19_0.png" />
</div>
</div>
<p>What are the key takeaways from this figure?</p>
<ol class="arabic simple">
<li><p>In general as the interaction becomes stronger the synergy increases (relative to the same main effects and correlation).</p></li>
<li><p>In general as the correlation increases synergy reduces (relative to the same main effects and interaction).</p></li>
<li><p>In the case with the greatest difference on contribution by the features, for example main effect coefficients A = 0.5 and B = 4, the synergy(A, B) &gt; synergy(B, A) as feature B contributes the most to the combined prediction and so A gets more help from B (than vice-versa) for the model predictions.</p></li>
<li><p>Symmetric synergy can exceed the natural values in the case of equal contribution of the features to the predictions (main effect A = B = 2).</p></li>
</ol>
</div>
<div class="section" id="Redundancy">
<h2>Redundancy<a class="headerlink" href="#Redundancy" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># create summary plot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">([</span><span class="s2">&quot;#30c1d7&quot;</span><span class="p">,</span> <span class="s2">&quot;#295e7e&quot;</span><span class="p">,</span> <span class="s2">&quot;#787878&quot;</span><span class="p">])</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">FacetGrid</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">long_sim1_data</span><span class="p">[</span><span class="n">long_sim1_data</span><span class="p">[</span><span class="s1">&#39;FACET Metric&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Redundancy&#39;</span><span class="p">],</span>
    <span class="n">col</span><span class="o">=</span><span class="s2">&quot;Interaction&quot;</span><span class="p">,</span>
    <span class="n">row</span><span class="o">=</span><span class="s1">&#39;Correlation&#39;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Metric Type&quot;</span><span class="p">,</span>
    <span class="n">margin_titles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">,</span>
    <span class="s2">&quot;x_val&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Metric Value&quot;</span><span class="p">,</span>
    <span class="n">estimator</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
    <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">g</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;(0.5, 4)&#39;</span><span class="p">,</span> <span class="s1">&#39;(1, 3)&#39;</span><span class="p">,</span> <span class="s1">&#39;(2, 2)&#39;</span><span class="p">,</span> <span class="s1">&#39;(3, 1)&#39;</span><span class="p">,</span> <span class="s1">&#39;(4, 0.5)&#39;</span><span class="p">])</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
<span class="n">g</span><span class="o">.</span><span class="n">set_axis_labels</span><span class="p">(</span><span class="s2">&quot;Main Effect Coefficients (A, B)&quot;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_Synergy_Redundancy_Tutorial_with_Facet_22_0.png" src="../_images/tutorial_Synergy_Redundancy_Tutorial_with_Facet_22_0.png" />
</div>
</div>
<p>What are the key takeaways from this figure?</p>
<ol class="arabic simple">
<li><p>In general as the correlation increases the redundancy increases (relative to the same main effects and interaction).</p></li>
<li><p>In general as the interaction increases the redundancy decreases (relative to the same main effects and correlation).</p></li>
<li><p>In the case with the greatest difference on contribution by the features, for example main effect coefficients A = 0.5 and B = 4, the redundancy(A, B) &gt; redundancy(B, A) as feature B “knows” more of what feature A does than vice-versa. In other words the model can tolerate loosing the information in A but not in B.</p></li>
<li><p>Symmetric redundancy can exceed the natural values in the case of equal contribution of the features to the predictions (main effect A = B = 2).</p></li>
</ol>
<p>Some additional points to keep in mind:</p>
<ul class="simple">
<li><p>Removing a redundant feature is unlikely to significantly reduce predictive performance, whereas removing a synergistic feature could significantly reduce predictive performance.</p></li>
<li><p>The example here uses linear correlation and interactions for simplicity. However, if the correlation or interaction between two features is non-linear this may not be identified through a typical exploratory data analysis.</p></li>
<li><p>For both correlation and interaction, the extent to which they are reflected in the redundancy or synergy for two features depends upon the fitted model. For example, if there is an interaction but the model does not learn this during training, then synergy will correspondingly be minimal.</p></li>
</ul>
</div>
</div>
<div class="section" id="How-overfitting-affects-the-accuracy-of-redundancy-and-synergy-estimates">
<h1>How overfitting affects the accuracy of redundancy and synergy estimates<a class="headerlink" href="#How-overfitting-affects-the-accuracy-of-redundancy-and-synergy-estimates" title="Permalink to this headline">¶</a></h1>
<p>In this second simulation study we are going to explore the values of synergy and redundancy as a function of regularization in a random forest. <strong>Note that for the sake of simplicity we will utilise the symmetric definitions of synergy and redundancy</strong>.</p>
<p>The main regularization parameter is the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>, which controls the tree depth. In general, the deeper the tree the more likely we are to overfit the data. Because we will apply cross-validation we can get a sense of how model performance improves and then degrades with <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> using the cross-validation curve.</p>
<p>For this second simulation case study, we use the following parameters for data generation:</p>
<ul class="simple">
<li><p>intercept (<span class="math notranslate nohighlight">\(\beta_0\)</span>) = <code class="docutils literal notranslate"><span class="pre">[0]</span></code></p></li>
<li><p>main effects (<span class="math notranslate nohighlight">\(\beta_1, \beta_2\)</span>) = <code class="docutils literal notranslate"><span class="pre">[1]</span></code></p></li>
<li><p>interaction (<span class="math notranslate nohighlight">\(\beta_3\)</span>) = <code class="docutils literal notranslate"><span class="pre">[3]</span></code></p></li>
<li><p>correlation (<span class="math notranslate nohighlight">\(\rho\)</span>) = <code class="docutils literal notranslate"><span class="pre">[0.5]</span></code></p></li>
</ul>
<p>We simulate 20 datasets with 1000 observations. The classifier used is a Random Forest with default hyperparameters, except as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span> <span class="pre">=</span> <span class="pre">[2,</span> <span class="pre">4,</span> <span class="pre">8,</span> <span class="pre">16,</span> <span class="pre">32]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span> <span class="pre">=</span> <span class="pre">[250]</span></code></p></li>
</ul>
<p>For each combination of parameters above we perform model fitting using 10 repeated 5-fold CV for each of the 20 simulated datasets.</p>
<p>The code used to generate the data presented is shown in the <a class="reference external" href="#Simulation-study-2-code">Appendix</a>. You can experiment with that code and perform your own simulation studies.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># load simulation study data</span>
<span class="n">val_curve_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;sphinx/source/tutorial/classification_sim2_cvcurve.csv&quot;</span><span class="p">)</span>
<span class="n">sim2_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;sphinx/source/tutorial/classification_sim2.csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;max_depth&quot;</span><span class="p">,</span> <span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">long_sim2_data</span> <span class="o">=</span> <span class="n">sim2_data</span><span class="p">[[</span><span class="s2">&quot;redundancy&quot;</span><span class="p">,</span> <span class="s2">&quot;synergy&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">long_sim2_data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;level_2&quot;</span><span class="p">:</span> <span class="s2">&quot;FACET metric&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;Redundany / Synergy&quot;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">best_max_depth</span> <span class="o">=</span> <span class="n">val_curve_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">val_curve_df</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">(),</span> <span class="s2">&quot;max_depth&quot;</span><span class="p">]</span>

<span class="c1"># plot cross-validation curve from Learner Ranker</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;max_depth&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;score&quot;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">val_curve_df</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;max_depth&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;mean CV AUC&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Cross-validation curve&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">best_max_depth</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>

<span class="c1"># create plot for redundancy and synergy as a function of max_depth</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">([</span><span class="s2">&quot;#30c1d7&quot;</span><span class="p">,</span> <span class="s2">&quot;#295e7e&quot;</span><span class="p">])</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;max_depth&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Redundany / Synergy&quot;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">long_sim2_data</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;FACET metric&quot;</span><span class="p">,</span>
    <span class="n">estimator</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
    <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Synergy and Redundancy as a function of max_depth&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">best_max_depth</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.lines.Line2D at 0x1e97b0d8a30&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_Synergy_Redundancy_Tutorial_with_Facet_26_1.png" src="../_images/tutorial_Synergy_Redundancy_Tutorial_with_Facet_26_1.png" />
</div>
</div>
<p>We can observe the following from the figure above:</p>
<ol class="arabic simple">
<li><p>Based on the cross-validation curve, the best choice of <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> is 5.</p></li>
<li><p>The value of synergy at the best <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> of 5 is around 46% which is lower than the largest estimate of 53% when we overfit (right of <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> = 5), and much greater than the smallest estimate of 30% when we underfit (left of <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> = 5).</p></li>
<li><p>The value of redundancy at the best <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> of 5 is around 27% which is higher than the smallest estimate of 23% when we overfit (right of <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> = 5), and lower than the highest estimate of 30% when we underfit (left of <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> = 5).</p></li>
</ol>
<p>This suggests for a pair of moderately correlated features with a moderate interaction and limited individual contributions, overfitting might cause us to over-estimate synergy (i.e., the model interprets noise as an interaction) and under-estimate redundancy, while underfitting can cause the opposite. As with all machine learning, identifying a well-tuned model is critical to obtaining appropriate estimates of synergy and redundancy.</p>
</div>
<div class="section" id="Summary">
<h1>Summary<a class="headerlink" href="#Summary" title="Permalink to this headline">¶</a></h1>
<p>We conducted two simulation studies using a simple controlled setting where we knew the amount of correlation, individual and combined contributions to a binary target.</p>
<ul class="simple">
<li><p>In the first simulation study we saw that the amount of correlation between two features as well as the strength of combined and independent contributions drive the balance between synergy and redundancy.</p></li>
<li><p>In the second simulation study we saw how both synergy and redundancy changed as a function of the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> parameter of our Random Forest classifier. For a pair of features with correlation and interaction, as <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> increased synergy increased and redundancy decreased.</p></li>
</ul>
</div>
<div class="section" id="What-can-you-do-next?">
<h1>What can you do next?<a class="headerlink" href="#What-can-you-do-next?" title="Permalink to this headline">¶</a></h1>
<p>There are several next steps that could be taken to gain further intuition regarding the capabilities of FACET:</p>
<ol class="arabic simple">
<li><p>Explore further values of main-effects, interaction and correlation between the two features used in the simulation studies.</p></li>
<li><p>Add further features to the simulation and explore what happens when you have features that are correlated but only one contributes to prediction (i.e., a purely redundant feature).</p></li>
<li><p>Try different learners and hyperparameters and see how the redundancy and synergy results change. <strong>Remember, the contributions of features to individual predictions is through the “eyes” of the model</strong>.</p></li>
</ol>
</div>
<div class="section" id="Appendix">
<h1>Appendix<a class="headerlink" href="#Appendix" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Data-simulation-code">
<h2>Data simulation code<a class="headerlink" href="#Data-simulation-code" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sim_interaction</span><span class="p">(</span>
    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">intercept</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">coef_1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">coef_2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">coef_3</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">corr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nb">type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;regression&#39;</span><span class="p">,</span>
<span class="p">):</span>

    <span class="c1"># two standard normal features for the interaction term in the linear predictor</span>
    <span class="c1"># mean and standard deviation of each feature</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">sd_mat</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="c1"># correlation matrix</span>
    <span class="n">corr_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="n">corr</span><span class="p">],</span> <span class="p">[</span><span class="n">corr</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

    <span class="c1"># calculate covariance</span>
    <span class="n">cov_mat</span> <span class="o">=</span> <span class="n">sd_mat</span><span class="o">*</span><span class="n">corr_mat</span><span class="o">*</span><span class="n">sd_mat</span>

    <span class="n">tmp_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">cov_mat</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">),</span>
        <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;feature_1&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_2&quot;</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="c1"># linear predictor</span>
    <span class="n">lp</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">intercept</span>
        <span class="o">+</span> <span class="n">coef_1</span> <span class="o">*</span> <span class="n">tmp_data</span><span class="o">.</span><span class="n">feature_1</span>
        <span class="o">+</span> <span class="n">coef_2</span> <span class="o">*</span> <span class="n">tmp_data</span><span class="o">.</span><span class="n">feature_2</span>
        <span class="o">+</span> <span class="n">coef_3</span> <span class="o">*</span> <span class="n">tmp_data</span><span class="o">.</span><span class="n">feature_1</span> <span class="o">*</span> <span class="n">tmp_data</span><span class="o">.</span><span class="n">feature_2</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>

        <span class="c1"># create target</span>
        <span class="n">tmp_data</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lp</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

    <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;classification&quot;</span><span class="p">:</span>

        <span class="c1"># convert to probability</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lp</span><span class="p">))</span>

        <span class="c1"># create target</span>
        <span class="n">tmp_data</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">prob</span> <span class="o">&lt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tmp_data</span>
</pre></div>
</div>
</div>
<div class="section" id="Simulation-study-1-code">
<h2>Simulation study 1 code<a class="headerlink" href="#Simulation-study-1-code" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># parameters for data sim</span>
<span class="n">coeffs</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]</span>
<span class="n">corr</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="n">intx</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">parm_grid</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">intx</span><span class="p">,</span> <span class="n">corr</span><span class="p">]))</span>
<span class="n">n_sims</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_parms</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parm_grid</span><span class="p">)</span>
<span class="n">full_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([])</span>

<span class="c1"># number of iterations for a set of conditions</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_parms</span><span class="p">):</span>

    <span class="c1"># iterate over hyperparameters</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sims</span><span class="p">):</span>

        <span class="nb">print</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="c1"># simulate train data</span>
        <span class="n">sim_df</span> <span class="o">=</span> <span class="n">sim_interaction</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                 <span class="n">intercept</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                 <span class="n">coef_1</span><span class="o">=</span><span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                                 <span class="n">coef_2</span><span class="o">=</span><span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                                 <span class="n">coef_3</span><span class="o">=</span><span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                                 <span class="n">corr</span><span class="o">=</span><span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
                                 <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;regression&#39;</span><span class="p">)</span>

        <span class="c1"># create classifier with required hyperparameters</span>
        <span class="n">rf_pipeline</span> <span class="o">=</span> <span class="n">RegressorPipelineDF</span><span class="p">(</span>
            <span class="n">regressor</span><span class="o">=</span><span class="n">RandomForestRegressorDF</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># use learner ranker to assess hyperparameters to create a validation curve for max_depth</span>
        <span class="n">crossfit</span> <span class="o">=</span> <span class="n">LearnerCrossfit</span><span class="p">(</span>
            <span class="n">pipeline</span><span class="o">=</span><span class="n">rf_pipeline</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">RepeatedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">3</span>
        <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sample</span> <span class="o">=</span> <span class="n">Sample</span><span class="p">(</span>
            <span class="n">observations</span><span class="o">=</span><span class="n">sim_df</span><span class="p">,</span>
            <span class="n">feature_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">],</span>
            <span class="n">target_name</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># do a straight crossfit with fit inspector</span>
        <span class="n">inspector</span> <span class="o">=</span> <span class="n">LearnerInspector</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">crossfit</span><span class="o">=</span><span class="n">crossfit</span><span class="p">)</span>

        <span class="c1"># obtain synergy</span>
        <span class="n">asym_smat</span> <span class="o">=</span> <span class="n">inspector</span><span class="o">.</span><span class="n">feature_synergy_matrix</span><span class="p">(</span><span class="n">symmetrical</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">sym_smat</span> <span class="o">=</span> <span class="n">inspector</span><span class="o">.</span><span class="n">feature_synergy_matrix</span><span class="p">(</span><span class="n">symmetrical</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># assemble results</span>
        <span class="n">tmp_results_syn</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span>
            <span class="s1">&#39;coeff_A&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
            <span class="s1">&#39;coeff_B&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
            <span class="s1">&#39;Interaction&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
            <span class="s1">&#39;Correlation&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
            <span class="s1">&#39;FACET Metric&#39;</span><span class="p">:</span> <span class="s2">&quot;Synergy&quot;</span><span class="p">,</span>
            <span class="s1">&#39;Asymmetric(A,B)&#39;</span><span class="p">:</span> <span class="n">asym_smat</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">],</span>
            <span class="s1">&#39;Asymmetric(B,A)&#39;</span><span class="p">:</span> <span class="n">asym_smat</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;feature_2&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_1&#39;</span><span class="p">],</span>
            <span class="s1">&#39;Symmetric&#39;</span><span class="p">:</span> <span class="n">sym_smat</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">],</span>
        <span class="p">})</span>
        <span class="n">full_results</span> <span class="o">=</span> <span class="n">full_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_results_syn</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># obtain redundancy</span>
        <span class="n">asym_rmat</span> <span class="o">=</span> <span class="n">inspector</span><span class="o">.</span><span class="n">feature_redundancy_matrix</span><span class="p">(</span><span class="n">symmetrical</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">sym_rmat</span> <span class="o">=</span> <span class="n">inspector</span><span class="o">.</span><span class="n">feature_redundancy_matrix</span><span class="p">(</span><span class="n">symmetrical</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">tmp_results_red</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span>
            <span class="s1">&#39;coeff_A&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
            <span class="s1">&#39;coeff_B&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
            <span class="s1">&#39;Interaction&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
            <span class="s1">&#39;Correlation&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
            <span class="s1">&#39;FACET Metric&#39;</span><span class="p">:</span> <span class="s2">&quot;Redundancy&quot;</span><span class="p">,</span>
            <span class="s1">&#39;Asymmetric(A,B)&#39;</span><span class="p">:</span> <span class="n">asym_rmat</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">],</span>
            <span class="s1">&#39;Asymmetric(B,A)&#39;</span><span class="p">:</span> <span class="n">asym_rmat</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;feature_2&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_1&#39;</span><span class="p">],</span>
            <span class="s1">&#39;Symmetric&#39;</span><span class="p">:</span> <span class="n">sym_rmat</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">],</span>
        <span class="p">})</span>
        <span class="n">full_results</span> <span class="o">=</span> <span class="n">full_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_results_red</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># for plotting</span>
<span class="n">full_results</span> <span class="o">=</span> <span class="n">full_results</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;coeff_A&quot;</span><span class="p">,</span> <span class="s2">&quot;coeff_B&quot;</span><span class="p">,</span> <span class="s2">&quot;Interaction&quot;</span><span class="p">,</span> <span class="s2">&quot;Correlation&quot;</span><span class="p">,</span> <span class="s2">&quot;FACET Metric&quot;</span><span class="p">])</span>
<span class="n">long_full_results</span> <span class="o">=</span> <span class="n">full_results</span><span class="p">[[</span><span class="s2">&quot;Asymmetric(A,B)&quot;</span><span class="p">,</span> <span class="s2">&quot;Asymmetric(B,A)&quot;</span><span class="p">,</span> <span class="s2">&quot;Symmetric&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">long_full_results</span><span class="p">[</span><span class="s1">&#39;x_val&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">long_full_results</span><span class="p">[</span><span class="s1">&#39;coeff_A&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">long_full_results</span><span class="p">[</span><span class="s1">&#39;coeff_A&#39;</span><span class="p">])</span>
<span class="n">long_full_results</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;level_5&quot;</span><span class="p">:</span> <span class="s2">&quot;Metric Type&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;Metric Value&quot;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">long_full_results</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;sphinx/source/tutorial/regression_sim1.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Simulation-study-2-code">
<h2>Simulation study 2 code<a class="headerlink" href="#Simulation-study-2-code" title="Permalink to this headline">¶</a></h2>
<p>First create a validation curve for <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># hyperparameters to investigate</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">33</span><span class="p">))</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="p">[</span><span class="mi">250</span><span class="p">]</span>

<span class="c1"># simulate train data</span>
<span class="n">sim_df</span> <span class="o">=</span> <span class="n">sim_interaction</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                         <span class="n">intercept</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                         <span class="n">coef_1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">coef_2</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">coef_3</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                         <span class="n">corr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                         <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">)</span>

<span class="c1"># create classifier with required hyperparameters</span>
<span class="n">rf_pipeline</span> <span class="o">=</span> <span class="n">ClassifierPipelineDF</span><span class="p">(</span>
    <span class="n">classifier</span><span class="o">=</span><span class="n">RandomForestClassifierDF</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">rf_grid</span> <span class="o">=</span> <span class="n">LearnerGrid</span><span class="p">(</span>
    <span class="n">pipeline</span><span class="o">=</span><span class="n">rf_pipeline</span><span class="p">,</span>
    <span class="n">learner_parameters</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">max_depth</span><span class="p">,</span>
                        <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="n">n_estimators</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># use learner ranker to assess hyperparameters to create a validation curve for max_depth</span>
<span class="n">ranker</span> <span class="o">=</span> <span class="n">LearnerRanker</span><span class="p">(</span>
    <span class="n">grids</span><span class="o">=</span><span class="p">[</span><span class="n">rf_grid</span><span class="p">],</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">RepeatedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sample</span> <span class="o">=</span> <span class="n">Sample</span><span class="p">(</span>
    <span class="n">observations</span><span class="o">=</span><span class="n">sim_df</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">],</span>
    <span class="n">target_name</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># grab data for the plot</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">ranker</span><span class="o">.</span><span class="n">summary_report</span><span class="p">()</span>
<span class="n">result</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;roc_auc_mean&#39;</span><span class="p">:</span> <span class="s1">&#39;score&#39;</span><span class="p">,</span> <span class="s1">&#39;classifier_max_depth&#39;</span><span class="p">:</span><span class="s1">&#39;max_depth&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># save dataset for plotting</span>
<span class="n">result</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;sphinx/source/tutorial/classification_sim2_cvcurve.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, we run a simulation to assess the change in synergy and redundancy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># hyperparameters to investigate</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">33</span><span class="p">))</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="p">[</span><span class="mi">250</span><span class="p">]</span>

<span class="n">parm_grid</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">max_depth</span><span class="p">,</span> <span class="n">n_estimators</span><span class="p">]))</span>
<span class="n">n_sims</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_parms</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parm_grid</span><span class="p">)</span>
<span class="n">full_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([])</span>

<span class="c1"># number of iterations for a set of conditions</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sims</span><span class="p">):</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

    <span class="c1"># simulate train data</span>
    <span class="n">sim_df</span> <span class="o">=</span> <span class="n">sim_interaction</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                             <span class="n">intercept</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                             <span class="n">coef_1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                             <span class="n">coef_2</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                             <span class="n">coef_3</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                             <span class="n">corr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                             <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">)</span>

    <span class="c1"># iterate over hyperparameters</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_parms</span><span class="p">):</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

        <span class="c1"># create classifier with required hyperparameters</span>
        <span class="n">clf</span> <span class="o">=</span> <span class="n">ClassifierPipelineDF</span><span class="p">(</span>
            <span class="n">classifier</span><span class="o">=</span><span class="n">RandomForestClassifierDF</span><span class="p">(</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                <span class="n">max_depth</span><span class="o">=</span><span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">n_estimators</span><span class="o">=</span><span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># run crossfit</span>
        <span class="n">crossfit</span> <span class="o">=</span> <span class="n">LearnerCrossfit</span><span class="p">(</span>
            <span class="n">pipeline</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">RepeatedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sample</span> <span class="o">=</span> <span class="n">Sample</span><span class="p">(</span>
            <span class="n">observations</span><span class="o">=</span><span class="n">sim_df</span><span class="p">,</span>
            <span class="n">feature_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">],</span>
            <span class="n">target_name</span><span class="o">=</span><span class="s1">&#39;target&#39;</span>
        <span class="p">))</span>

        <span class="c1"># do a straight crossfit with fit inspector</span>
        <span class="n">inspector</span> <span class="o">=</span> <span class="n">LearnerInspector</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">crossfit</span><span class="o">=</span><span class="n">crossfit</span><span class="p">)</span>

        <span class="c1"># obtain synergy and redundancy</span>
        <span class="n">redundancy_matrix</span> <span class="o">=</span> <span class="n">inspector</span><span class="o">.</span><span class="n">feature_redundancy_matrix</span><span class="p">(</span><span class="n">symmetrical</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">synergy_matrix</span> <span class="o">=</span> <span class="n">inspector</span><span class="o">.</span><span class="n">feature_synergy_matrix</span><span class="p">(</span><span class="n">symmetrical</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># assemble results</span>
        <span class="n">tmp_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                   <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="n">parm_grid</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                   <span class="s1">&#39;redundancy&#39;</span><span class="p">:</span> <span class="n">redundancy_matrix</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">],</span>
                   <span class="s1">&#39;synergy&#39;</span><span class="p">:</span> <span class="n">synergy_matrix</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">],</span>
                   <span class="s1">&#39;y_mean&#39;</span><span class="p">:</span> <span class="n">sim_df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">mean</span><span class="p">()})</span>

        <span class="n">full_results</span> <span class="o">=</span> <span class="n">full_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_results</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># output to a csv file - and use in generating notebook</span>
<span class="n">full_results</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;sphinx/source/tutorial/classification_sim2.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="Scikit-learn_classifier_summaries_using_FACET.html" title="previous page">Standard Scikit-learn Classification Summary with FACET</a>
    <a class='right-next' id="next-link" href="../contribution_guide.html" title="next page">Development Guidelines</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Boston Consulting Group (BCG).<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>